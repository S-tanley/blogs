<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Reading Notes for SmartMoE | Stanley's Blog</title><meta name="author" content="Stanley Zheng"><meta name="copyright" content="Stanley Zheng"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Summary Abstract &amp; Introduction &amp; Background and Motivation Deep neural network（DNN）现在越来越大，除了dense model，就是比较传统的model之外，越来越多的人开始关注sparsely activated model。针对dense model，之前有很多auto-parallelizati">
<meta property="og:type" content="article">
<meta property="og:title" content="Reading Notes for SmartMoE">
<meta property="og:url" content="https://s-tanley.github.io/blogs/2025/03/27/SmartMoE/index.html">
<meta property="og:site_name" content="Stanley&#39;s Blog">
<meta property="og:description" content="Summary Abstract &amp; Introduction &amp; Background and Motivation Deep neural network（DNN）现在越来越大，除了dense model，就是比较传统的model之外，越来越多的人开始关注sparsely activated model。针对dense model，之前有很多auto-parallelizati">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s-tanley.github.io/blogs/img/MyProfilePicture.JPG">
<meta property="article:published_time" content="2025-03-27T05:00:00.000Z">
<meta property="article:modified_time" content="2025-03-30T23:46:21.644Z">
<meta property="article:author" content="Stanley Zheng">
<meta property="article:tag" content="MLSys">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s-tanley.github.io/blogs/img/MyProfilePicture.JPG"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Reading Notes for SmartMoE",
  "url": "https://s-tanley.github.io/blogs/2025/03/27/SmartMoE/",
  "image": "https://s-tanley.github.io/blogs/img/MyProfilePicture.JPG",
  "datePublished": "2025-03-27T05:00:00.000Z",
  "dateModified": "2025-03-30T23:46:21.644Z",
  "author": [
    {
      "@type": "Person",
      "name": "Stanley Zheng",
      "url": "https://s-tanley.github.io/blogs/"
    }
  ]
}</script><link rel="shortcut icon" href="/blogs/img/favicon.png"><link rel="canonical" href="https://s-tanley.github.io/blogs/2025/03/27/SmartMoE/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/blogs/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/blogs/',
  algolia: undefined,
  localSearch: {"path":"/blogs/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"No results found for: ${query}","hits_stats":"${hits} articles found"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Reading Notes for SmartMoE',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/blogs/img/MyProfilePicture.JPG" onerror="this.onerror=null;this.src='/blogs/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/blogs/archives/"><div class="headline">Articles</div><div class="length-num">47</div></a><a href="/blogs/tags/"><div class="headline">Tags</div><div class="length-num">11</div></a><a href="/blogs/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="https://s-tanley.github.io"><i class="fa-fw fas fa-id-badge"></i><span> Stanley Zheng</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/blogs/"><img class="site-icon" src="/blogs/img/MyProfilePicture.JPG" alt="Logo"><span class="site-name">Stanley's Blog</span></a><a class="nav-page-title" href="/blogs/"><span class="site-name">Reading Notes for SmartMoE</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="https://s-tanley.github.io"><i class="fa-fw fas fa-id-badge"></i><span> Stanley Zheng</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Reading Notes for SmartMoE</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-03-27T05:00:00.000Z" title="Created 2025-03-27 00:00:00">2025-03-27</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-03-30T23:46:21.644Z" title="Updated 2025-03-30 18:46:21">2025-03-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/blogs/categories/Reading-Paper/">Reading Paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1>Summary</h1>
<h2 id="Abstract-Introduction-Background-and-Motivation">Abstract &amp; Introduction &amp; Background and Motivation</h2>
<p>Deep neural network（DNN）现在越来越大，除了dense model，就是比较传统的model之外，越来越多的人开始关注sparsely activated model。针对dense model，之前有很多auto-parallelization的方法，但是这些方法对sparsely activated model，比如说MoE架构的模型就没那么好用了。所以他们主要做的就是实现对sparsely activated model做自动并行的分布式训练的方法。</p>
<p>Intro就先说一下来龙去脉，就众所周知，scaling law目前对DNN一直没有失效，所以各家基本上就是一直往上堆参数。但模型变大了就练不动了，所以就要找efficient method去做训练。一种就是从系统上，你去想办法去做并行训练，这样相同的计算资源，相同的时间，你能训练更大模型。要不然就是你对模型做改进，比如说MoE，虽然参数量很大，但因为每次训练的时候都只用activate一部分参数，所以就训练开销会降下来。</p>
<p>他们想说的就是没人把这两个结合起来，或者说有人在做MoE的时候，顺便针对他们的MoE有做这种并行训练的优化，但是没有太多去做通用一些的，automatic的并行方法给MoE。作者就说现有的模型都用是specific expert parallelism，但是这个方法又会影响training efficiency，是有一些方法来降低这个expert parallelism的cost，但是他们都“require special system expertise”，其实就还是再讲通用性的问题。然后又讲了自动化的问题，就说现有的automatic parallelization training systems都是为dense model服务的。这些基本都是在说research gap，就当前这个领域的空缺，或者也是一个为什么作者他们要做这个的原因。</p>
<img src="./SmartMoE/CleanShot 2025-03-27 at 14.51.39.png" alt="CleanShot 2025-03-27 at 14.51.39" style="zoom:67%;" />
<p>这里放了个图，大概展示了一下dense model和MoE model的区别。</p>
<p>MoE有这么一个比较独特的结构，肯定就有一些独特的property。这里作者强调的是“dynamic and imbalanced property”。其实也很好理解，每次不一样的数据，gate选的expert就不一样，就很明显dynamic。然后肯定有的experts用的多，有的experts用的少，这就是imbalanced。而且这些都是和每次的数据直接相关的，所以他们强调了一个概念：<strong>data-sensitive</strong>。</p>
<p>既然MoE有data- sensitive的性质，那么当前的parallelization</p>
<p>approaches肯定就有不好的地方。这里说了两个limitation：</p>
<ul>
<li>
<p><strong>Limited Optimization Space</strong></p>
<p>这个说的是，data- sensitive可以让我们做更多的优化，但是现在的并没有考虑这么多可以做优化的地方，因为他们是base dense model的。</p>
</li>
<li>
<p><strong>Large Searching Overhead</strong></p>
<p>MoE因为data- sensitive，所以每次各个expert的workload都不一样，所以其实每次的execution plan应该也都不一样，所以我们希望可以每次都换到一个合适的execution plan。但是现在方法，用一些规划方法，算plan的时间太久了，很明显就没法满足这种比较高的换plan的方法。</p>
</li>
</ul>
<p>他们的方法就是我先算一堆比较好的plan，叫做<strong>static pool</strong>，然后又用了一个很快的算法去实时从这个pool里选plan。同时，他们还实现了一种机制，我也不知道该不该叫它一种机制，叫做<strong>awareness of workload</strong>。反正就是可以知道每个experts的workload，这样根据这个我们就可以选那些experts放到一个机器上，或者我们应该怎么并行。</p>
<p>在background里还介绍了各种并行，什么data parallelism（DP）， pipeline model parallelism（PP）， tensor model parallelism（TP）， expert parallelism（EP）。反正关于并行这里，就名称不统一，基本上就是横着切模型（PP），竖着切模型（TP），或者复制很多歌模型（DP）。EP是“a combination of Data Parallelism and Tensor Model Parallelism specialized for the MoE scenario”。这里也给了图，也算清楚吧。</p>
<img src="./SmartMoE/CleanShot 2025-03-27 at 16.07.46.png" alt="CleanShot 2025-03-27 at 16.07.46" style="zoom:67%;" />
<p>主要还是图c，MoE part竖着切的，所谓的TP，但是Multi-Head那里又是复制了很多块，所以可以做DP。其实很合理的，因为你想MoE每次只用一个expert，但是前面的attention操作每一次都要做。所以前面每次都要做的我们用DP，后面E个expert只选一个的我们用TP。如果运气好，我们E个data做数据并行，到gate的时候正好assign到E个不同的experts，十分完美。</p>
<p>当然我们基本都用<strong>Hybrid Parallelism</strong>，就把不同的parallelism拼起来，你是怎么拼的，就是一个 <strong>parallel execution plan</strong>。也有一些automatic parallelization，但是time- consuming。</p>
<p>他们总结了关于提出一个automatic parallelization training system的难点：</p>
<ul>
<li>
<p><strong>Space of Hybrid Parallelism</strong></p>
<p>一个sytem不一定可以用所有的并行技术，你要知道这个space有多大，而且要尽量让他大。</p>
</li>
<li>
<p><strong>Performance Modeling</strong></p>
<p>怎么知道你选出来的plan好还是差。</p>
</li>
<li>
<p><strong>Searching Algorithm</strong></p>
<p>怎么从space里快速的选。</p>
</li>
</ul>
<img src="./SmartMoE/CleanShot 2025-03-27 at 16.30.16.png" alt="CleanShot 2025-03-27 at 16.30.16" style="zoom:67%;" />
<p>Figure 3我感觉就是非常清楚的说了为什么要change plan，为什么要workload aware performance modeling。</p>
<h2 id="Overview-Enlarged-Space-for-Hybrid-Parallelism">Overview &amp; Enlarged Space for Hybrid Parallelism</h2>
<p>“Beyond prior works that generate optimal execution plans based on <em>model</em> architecture and <em>hardware</em> specification, we take the <strong>workload</strong> into account for data-sensitive models.”</p>
<img src="./SmartMoE/CleanShot 2025-03-28 at 15.37.41.png" alt="CleanShot 2025-03-28 at 15.37.41" style="zoom:67%;" />
<p>这里分阶段讲了一下Two-Stage Auto-Parallelization。</p>
<p>第一个阶段是<strong>Offline Pool Construction</strong>。就是构建一个plan <strong>pool</strong>，都是一些比较好的execution plans。需要注意的就是他专门选的是那种相互之间比较好换的，要不然肯定不可行。</p>
<p>第二个阶段就是<strong>Online Adaptive Parallelization</strong>。这个时候就是已经开始训练了，就是用一个轻量级的算法去实时的找合适的execution plan。</p>
<p>这里有个概念感觉要提一下，<strong>expert slot</strong>，就是对于每一个expert（FFN）是用的什么并行。</p>
<img src="./SmartMoE/CleanShot 2025-03-28 at 16.08.47.png" alt="CleanShot 2025-03-28 at 16.08.47" style="zoom:70%;" />
<p>还有一个concrete example，但其实我有点没看懂。</p>
<img src="./SmartMoE/CleanShot 2025-03-28 at 17.26.05.png" alt="CleanShot 2025-03-28 at 17.26.05" style="zoom:67%;" />
<p>还说了一个<strong>expert placement</strong>，我感觉这个和Helix<a href="Helix">2</a>做的差不多，只不过Helix主要是在说inference，这个主要说的是训练而已。</p>
<h2 id="Offline-Pool-Construction-Online-Adaptive-Parallelization">Offline Pool Construction &amp;  Online Adaptive Parallelization</h2>
<h2 id="Evaluation-Related-Work-Conclusion">Evaluation &amp; Related Work &amp; Conclusion</h2>
<h1>Thoughts</h1>
<h2 id="About-their-method">About their method</h2>
<p>他这个方法我感觉主要应该还是侧重在这个automatic这一块，就是想要提出一个比较通用的方法，他在文章里我感觉也是一直在暗暗强调。</p>
<p>他们方法感觉也就是他们自己说的那个contribution：</p>
<ol>
<li>更多的并行组合方法，所谓的“enlarge the combination space of hybrid parallelism”。</li>
<li>Offline构建一个execution pool，online的时候用一个light-weight算法能实时从pool里选好的。</li>
<li>实现2需要“awareness of workload”，还需要一个light- weight算法。</li>
</ol>
<p>基本上就是这些。</p>
<h2 id="About-MoE-Framework">About MoE Framework</h2>
<p>有关MoE架构那里，有一点点跟我之前的理解稍有出入。他的MoE网络每一次经过gate，只会assign到<strong>一个</strong>最合适的expert。我之前的理解是可以随便组合expert，尤其是这个explicitly说了，一个FFN就是一个expert，也就是说expert之间应该是没有communication的。我之前的理解有点像backbone，backbone就是随机冻住一部分参数，就也是为了能够去训练比较大的网络。然后MoE的就是网络只有第一层是全连接，后面的不是全连接，但是我们gate去选expert其实就是选FFN的第一层的node。但不得不说现在看完他这种独立的说法，我觉得我以前的理解确实是有点误区，毕竟就是如果不是全连接的话，你怎么连接又是个问题。我现在就每个FFN就是个expert，然后都一样都是全连接网络，相互独立的，然后每次选一个最合适的，确实就是在实际训练的时候可行性更高。尤其是你要memory efficient，你有的时候要offload到别的地方去储存，然后在用的时候再load回来，确实需要一个个expert独立。</p>
<p>不过我现在就在想，每一个FFN反正就是都是全连接嘛，最后我把一些week connection直接drop掉呢。不知道distill是不是这么干的。</p>
<h2 id="About-Expert-Parallelism">About Expert Parallelism</h2>
<p>就是如果我们有这个gata了，其实就是说我们大概知道每个expert在一个workload里被用几次，那有没有可能我们把用的次数多的expert复制几个，就他们在做一个小的DP，这样是不是当用几个data同时assign到同一个expert的时候不用等了。或者至少inference的时候我们可以这么搞。</p>
<p>他这个Figure 5，我也是有点小问题，每一层的experts一定要一样数量，呀这个layer的意思是一个expert里面的层数还是experts的层数，有点不清楚，但是我还是比较倾向于一个expert（FFN）的层数</p>
<h2 id="Confusion-Guess">Confusion &amp; Guess</h2>
<p>这篇文章里比较重要的一个执行单元是“worker”，但其实我也没太懂他这一个worker到底是什么，我猜可能是一个GPU或者一个node。如果这样的话反正应该也要有一个assign任务的节点了。</p>
<h1>Reference</h1>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://s-tanley.github.io/blogs">Stanley Zheng</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://s-tanley.github.io/blogs/2025/03/27/SmartMoE/">https://s-tanley.github.io/blogs/2025/03/27/SmartMoE/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/blogs/tags/MLSys/">MLSys</a></div><div class="post-share"><div class="social-share" data-image="/blogs/img/MyProfilePicture.JPG" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/blogs/2025/03/26/GitHub%20%E5%AE%9E%E7%8E%B0%E5%A4%9A%20page%20sit/" title="GitHub 实现多 page site（Hexo框架）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">GitHub 实现多 page site（Hexo框架）</div></div><div class="info-2"><div class="info-item-1">如果你是用通过网上搜到的一些教程去 GitHub 上实现你自己的个人主页的话，你可能会发现大家都会强调你把你的 GitHub repo 的名字命名为 username.github.io。但实际上你可以在任意把任意的 repo 设置成你的项目主页，网上你可以搜到几个相关 GitHub 设置多 page 的帖子，随便放在这里一个，感兴趣可以去再看看。 总之，如果你只想把你基于 Hexo 的 blog deploy 到 GitHub 的话，很简单，只需要改两个 config。 在你的 _config.yml 文件里，把 url 改成 https://&lt;username&gt;.github.io/&lt;reponame&gt;。然后再加一个 root , 这个填成 /&lt;reponame&gt;/ 。其他就正常配置就好了。  我唯一遇到的，可能会出问题的地方，是在那个 page setting 那里。  这里可能不能用 GitHub action，不过我也不确定，但我之前调到 GitHub action 的时候会出问题。如果你发现你 deploy 到 github...</div></div></div></a><a class="pagination-related" href="/blogs/2025/03/28/FasterMoE/" title="Reading Notes for FasterMoE"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">Reading Notes for FasterMoE</div></div><div class="info-2"><div class="info-item-1">Summary Abstract &amp; Introduction &amp;  Background and Challenges 前面又是简单介绍MoE，基本都一样。 这个也是training方向的，说了三个challenges：   dynamic load imbalance 在intro里，叫Dynamic expert selection，就也比较明显，就是每次选的experts不一样。   inefficient synchronous execution mode 在intro里，叫Inefficient synchronous operations，就是expert有dependency，就需要别的worker的data，要等。   congested all-to-all communication 在intro里，叫Mismatch of model design and network topology，感觉他的意思是现在的system只管摆放experts的computation...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/blogs/2025/04/07/AllReduce%20&%20Bucketing/" title="AllReduce &amp; Bucketing"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-07</div><div class="info-item-2">AllReduce &amp; Bucketing</div></div><div class="info-2"><div class="info-item-1">本文主要介绍了 AllReduce 和 Bucketing 分别是什么，和他们之间的联系。 一、AllReduce 是什么？ AllReduce 是分布式训练中的一种集体通信操作， 用于在多个 GPU（worker）之间同步张量（通常是梯度）。 典型流程如下：  每个 GPU 独立计算自己的梯度张量（如 grad）。 所有 GPU 通过 AllReduce 操作，将各自的张量求和/平均，获得全局一致的梯度。 每个 GPU 使用这个同步后的梯度更新模型参数。  AllReduce 是数据并行训练中实现模型同步的关键机制。  二、为什么 AllReduce 会成为性能瓶颈？  模型中参数众多，梯度张量数量也很多。 每个张量如果单独 AllReduce，通信次数极多。 小张量通信无法充分利用带宽，且频繁启动通信带来显著延迟（latency）。   三、Bucketing 是什么？ Bucketing 是一种优化 AllReduce 通信效率的策略， 将多个小张量合并成一个大 “bucket”，再一次性执行 AllReduce。 核心思想：Batch Small Reduces...</div></div></div></a><a class="pagination-related" href="/blogs/2025/05/15/Orca/" title="Reading Notes for Orca"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-15</div><div class="info-item-2">Reading Notes for Orca</div></div><div class="info-2"><div class="info-item-1">This is the reading notes for the ORCA: A Distributed Serving System for Transformer-Based Generative Models. This is an OSDI conference paper from 2022. Almost all the authors come from South Korea, and actually, this is the first time I have read papers written by Koreans. Summary Abstract &amp; Introduction &amp; Background The paper is focused on the inference serving, they point out that the existing system is not good enough for transformer-based models. So, they propose a new method...</div></div></div></a><a class="pagination-related" href="/blogs/2025/04/07/MoE%20%E4%B8%AD%20All-to-All%20%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6/" title="MoE 中 All-to-All 通信机制"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-07</div><div class="info-item-2">MoE 中 All-to-All 通信机制</div></div><div class="info-2"><div class="info-item-1">本文主要介绍了 All-to-All 通信机制，以及为什么需要这个机制。 一、All-to-All 是什么？ 在分布式 Mixture-of-Experts（MoE）模型中，All-to-All 是一种通信操作， 用于在多个 GPU 之间交换 token 和专家（Expert）之间的数据。 每个 GPU 上都有输入 token，而每个 Expert 分布在多个不同的 GPU 上。 Gate 网络决定每个 token 应该由哪些专家处理，因此 token 需要被动态发送到目标 Expert 所在的 GPU。 这正是 All-to-All：每个 GPU 既向其他 GPU 发送数据，也接收来自其他 GPU 的数据。  二、为什么 MoE 模型需要 All-to-All？ 1. Expert 是独立的，但 Token 是全局的  每个 Expert 的参数是本地的，只存在于某个 GPU 上。 但 token 是通过数据并行划分的，分布在所有 GPU 上。 每个 token 的 gate 结果可能指向任意 GPU 上的 Expert。  因此，token 必须被跨设备发送到它所选中的...</div></div></div></a><a class="pagination-related" href="/blogs/2025/03/28/FasterMoE/" title="Reading Notes for FasterMoE"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-28</div><div class="info-item-2">Reading Notes for FasterMoE</div></div><div class="info-2"><div class="info-item-1">Summary Abstract &amp; Introduction &amp;  Background and Challenges 前面又是简单介绍MoE，基本都一样。 这个也是training方向的，说了三个challenges：   dynamic load imbalance 在intro里，叫Dynamic expert selection，就也比较明显，就是每次选的experts不一样。   inefficient synchronous execution mode 在intro里，叫Inefficient synchronous operations，就是expert有dependency，就需要别的worker的data，要等。   congested all-to-all communication 在intro里，叫Mismatch of model design and network topology，感觉他的意思是现在的system只管摆放experts的computation...</div></div></div></a><a class="pagination-related no-desc" href="/blogs/2025/05/27/SGLang/" title="Reading Notes for SGLang"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-27</div><div class="info-item-2">Reading Notes for SGLang</div></div></div></a><a class="pagination-related" href="/blogs/2025/06/10/Resource%20I%20have%20for%20MLSys/" title="Resource I Have for MLSys"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-10</div><div class="info-item-2">Resource I Have for MLSys</div></div><div class="info-2"><div class="info-item-1">This is like a guidance page for the resources I know for MLSys, I’ll give a brief introduction to each of them and list the link here. The resources will contain books, papers, and notes I wrote. Books AI System This book is more about the hardware. I think it’s a little bit like for ECE students. I haven’t read it all yet, but I think you can find some useful topics here, such as the introduction to Nvidia GPUs, the Tensor Core, stream multiprocessors, and how the GPU actually do to...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comments</span></div><div class="comment-switch"><span class="first-comment">Giscus</span><span id="switch-btn"></span><span class="second-comment">Utterances</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div><div><div id="utterances-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/blogs/img/MyProfilePicture.JPG" onerror="this.onerror=null;this.src='/blogs/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Stanley Zheng</div><div class="author-info-description">Hi, I am Stanley. I am currently a CS student in the University of Wisconsin-Madison. </div><div class="site-data"><a href="/blogs/archives/"><div class="headline">Articles</div><div class="length-num">47</div></a><a href="/blogs/tags/"><div class="headline">Tags</div><div class="length-num">11</div></a><a href="/blogs/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/S-tanley"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://s-tanley.github.io" target="_blank" title="Homepage"><i class="fas fa-id-badge" style="color: #808080;"></i></a><a class="social-icon" href="https://github.com/S-tanley" target="_blank" title="Github"><i class="fab fa-github" style="color: #808080;"></i></a><a class="social-icon" href="mailto:zbowen936@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #808080;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Summary</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract-Introduction-Background-and-Motivation"><span class="toc-number">1.1.</span> <span class="toc-text">Abstract &amp; Introduction &amp; Background and Motivation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Overview-Enlarged-Space-for-Hybrid-Parallelism"><span class="toc-number">1.2.</span> <span class="toc-text">Overview &amp; Enlarged Space for Hybrid Parallelism</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Offline-Pool-Construction-Online-Adaptive-Parallelization"><span class="toc-number">1.3.</span> <span class="toc-text">Offline Pool Construction &amp;  Online Adaptive Parallelization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Evaluation-Related-Work-Conclusion"><span class="toc-number">1.4.</span> <span class="toc-text">Evaluation &amp; Related Work &amp; Conclusion</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">Thoughts</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#About-their-method"><span class="toc-number">2.1.</span> <span class="toc-text">About their method</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#About-MoE-Framework"><span class="toc-number">2.2.</span> <span class="toc-text">About MoE Framework</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#About-Expert-Parallelism"><span class="toc-number">2.3.</span> <span class="toc-text">About Expert Parallelism</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Confusion-Guess"><span class="toc-number">2.4.</span> <span class="toc-text">Confusion &amp; Guess</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">Reference</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blogs/2025/09/09/Notes---Operating%20Systems:%20Three%20Easy%20Piece%EF%BC%88UW-Madison%20CS%20537%EF%BC%89/" title="Notes---Operating Systems: Three Easy Piece（UW-Madison CS 537）">Notes---Operating Systems: Three Easy Piece（UW-Madison CS 537）</a><time datetime="2025-09-09T05:00:00.000Z" title="Created 2025-09-09 00:00:00">2025-09-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blogs/2025/08/21/Using%20Clip%20to%20Music%20Generation/" title="Using Clip to Music Generation">Using Clip to Music Generation</a><time datetime="2025-08-21T05:00:00.000Z" title="Created 2025-08-21 00:00:00">2025-08-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blogs/2025/08/16/%E7%90%86%E8%A7%A3%20Zero-Shot,%20One-Shot,%20%E5%92%8C%20Few-Shot%20%E5%AD%A6%E4%B9%A0/" title="理解 Zero-Shot, One-Shot, 和 Few-Shot 学习">理解 Zero-Shot, One-Shot, 和 Few-Shot 学习</a><time datetime="2025-08-16T05:00:00.000Z" title="Created 2025-08-16 00:00:00">2025-08-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blogs/2025/08/14/Notes---%E8%8B%8F%E5%89%91%E6%9E%97%E5%8D%9A%E5%AE%A2%EF%BC%88%E8%AF%8D%E5%90%91%E9%87%8F%E4%B8%8EEmbedding%E6%8A%80%E6%9C%AF%EF%BC%89/" title="Notes---苏剑林博客（词向量与Embedding技术）">Notes---苏剑林博客（词向量与Embedding技术）</a><time datetime="2025-08-14T05:00:00.000Z" title="Created 2025-08-14 00:00:00">2025-08-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blogs/2025/08/11/Notes---%E8%8B%8F%E5%89%91%E6%9E%97%E5%8D%9A%E5%AE%A2%EF%BC%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%EF%BC%89/" title="Notes---苏剑林博客（神经网络与深度学习基础）">Notes---苏剑林博客（神经网络与深度学习基础）</a><time datetime="2025-08-11T05:00:00.000Z" title="Created 2025-08-11 00:00:00">2025-08-11</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Stanley Zheng</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll to Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/blogs/js/utils.js"></script><script src="/blogs/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (false) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = {"data-mapping":"pathname","data-input-position":"top","data-reactions-enabled":1,"data-strict":1}

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'S-tanley/blogs',
      'data-repo-id': 'R_kgDOOPJb6Q',
      'data-category-id': 'DIC_kwDOOPJb6c4CohlA',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null
  const getUtterancesTheme = theme => theme === 'dark' ? 'photon-dark' : 'github-light'

  const loadUtterances = (el = document, key) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyUtterances = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const config = {
      src: 'https://utteranc.es/client.js',
      repo: 'S-tanley/blogs',
      theme: getUtterancesTheme(document.documentElement.getAttribute('data-theme')),
      crossorigin: 'anonymous',
      async: true,
      ...option,
      'issue-term': isShuoshuo ? key : (option && option['issue-term']) || 'pathname'
    }

    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => ele.setAttribute(key, value))
    el.querySelector('#utterances-wrap').appendChild(ele)
  }

  const changeUtterancesTheme = theme => {
    const iframe = document.querySelector('#utterances-wrap iframe')
    if (iframe) {
      const message = {
        type: 'set-theme',
        theme: getUtterancesTheme(theme)
      };
      iframe.contentWindow.postMessage(message, 'https://utteranc.es')
    }
  }

  btf.addGlobalFn('themeChange', changeUtterancesTheme, 'utterances')

  if (isShuoshuo) {
    'Giscus' === 'Utterances'
      ? window.shuoshuoComment = { loadComment: loadUtterances }
      : window.loadOtherComment = loadUtterances
    return
  }
  
  if ('Giscus' === 'Utterances' || !false) {
    if (false) btf.loadComment(document.getElementById('utterances-wrap'), loadUtterances)
    else loadUtterances()
  } else {
    window.loadOtherComment = loadUtterances
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/blogs/js/search/local-search.js"></script></div></div></body></html>