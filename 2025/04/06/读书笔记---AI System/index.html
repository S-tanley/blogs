<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>读书笔记---AI System（1） | Stanley's Blog</title><meta name="author" content="Stanley Zheng"><meta name="copyright" content="Stanley Zheng"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="这本书发现的也算，比较曲折，是看到有一个人写的一篇知乎里推荐了一位博主吧，叫 ZOMI酱。虽然是在知乎发现的，但是他基本上是一个视频博主，所以B站看的话更方便，看了一个介绍视频之后发现了他这个AISys的开源书，发现直接看书也可以。目前感觉还是不错的。 AI 系统概述 这个 chapter 里面就全是介绍，感觉没啥说的，但反正读起来还算很顺，我觉得这种教科书性质的读起来很顺就很可以了。但如果你完全">
<meta property="og:type" content="article">
<meta property="og:title" content="读书笔记---AI System（1）">
<meta property="og:url" content="https://s-tanley.github.io/blogs/2025/04/06/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0---AI%20System/index.html">
<meta property="og:site_name" content="Stanley&#39;s Blog">
<meta property="og:description" content="这本书发现的也算，比较曲折，是看到有一个人写的一篇知乎里推荐了一位博主吧，叫 ZOMI酱。虽然是在知乎发现的，但是他基本上是一个视频博主，所以B站看的话更方便，看了一个介绍视频之后发现了他这个AISys的开源书，发现直接看书也可以。目前感觉还是不错的。 AI 系统概述 这个 chapter 里面就全是介绍，感觉没啥说的，但反正读起来还算很顺，我觉得这种教科书性质的读起来很顺就很可以了。但如果你完全">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s-tanley.github.io/blogs/img/MyProfilePicture.JPG">
<meta property="article:published_time" content="2025-04-06T05:00:00.000Z">
<meta property="article:modified_time" content="2025-05-07T16:08:32.635Z">
<meta property="article:author" content="Stanley Zheng">
<meta property="article:tag" content="MLSys">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s-tanley.github.io/blogs/img/MyProfilePicture.JPG"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "读书笔记---AI System（1）",
  "url": "https://s-tanley.github.io/blogs/2025/04/06/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0---AI%20System/",
  "image": "https://s-tanley.github.io/blogs/img/MyProfilePicture.JPG",
  "datePublished": "2025-04-06T05:00:00.000Z",
  "dateModified": "2025-05-07T16:08:32.635Z",
  "author": [
    {
      "@type": "Person",
      "name": "Stanley Zheng",
      "url": "https://s-tanley.github.io/blogs/"
    }
  ]
}</script><link rel="shortcut icon" href="/blogs/img/favicon.png"><link rel="canonical" href="https://s-tanley.github.io/blogs/2025/04/06/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0---AI%20System/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/blogs/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/blogs/',
  algolia: undefined,
  localSearch: {"path":"/blogs/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"No results found for: ${query}","hits_stats":"${hits} articles found"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '读书笔记---AI System（1）',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/blogs/img/MyProfilePicture.JPG" onerror="this.onerror=null;this.src='/blogs/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/blogs/archives/"><div class="headline">Articles</div><div class="length-num">46</div></a><a href="/blogs/tags/"><div class="headline">Tags</div><div class="length-num">11</div></a><a href="/blogs/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="https://s-tanley.github.io"><i class="fa-fw fas fa-id-badge"></i><span> Stanley Zheng</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/blogs/"><img class="site-icon" src="/blogs/img/MyProfilePicture.JPG" alt="Logo"><span class="site-name">Stanley's Blog</span></a><a class="nav-page-title" href="/blogs/"><span class="site-name">读书笔记---AI System（1）</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="https://s-tanley.github.io"><i class="fa-fw fas fa-id-badge"></i><span> Stanley Zheng</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">读书笔记---AI System（1）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-04-06T05:00:00.000Z" title="Created 2025-04-06 00:00:00">2025-04-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-05-07T16:08:32.635Z" title="Updated 2025-05-07 11:08:32">2025-05-07</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/blogs/categories/%E4%B9%A6%E8%AF%84/">书评</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>这本书发现的也算，比较曲折，是看到有一个人写的一篇知乎里推荐了一位博主吧，叫 <a target="_blank" rel="noopener" href="https://space.bilibili.com/517221395">ZOMI酱</a>。虽然是在知乎发现的，但是他基本上是一个视频博主，所以B站看的话更方便，看了一个介绍视频之后发现了他这个AISys的开源书，发现直接看书也可以。目前感觉还是不错的。</p>
<h1>AI 系统概述</h1>
<p>这个 chapter 里面就全是介绍，感觉没啥说的，但反正读起来还算很顺，我觉得这种教科书性质的读起来很顺就很可以了。但如果你完全没有任何背景知识的话，估计读完就读完了，也不会有什么感受，如果你有一些背景知识的话，就算是帮你梳理一下体系。</p>
<h1>AI 硬件体系结构</h1>
<h2 id="AI-计算体系概述">AI 计算体系概述</h2>
<h3 id="AI-计算模式">AI 计算模式</h3>
<p>这里遇到了一些以前不知道的知识。</p>
<p>模型量化和网络剪枝，这两个技术都是为了解决模型太大，占用的内存太多的问题。</p>
<img src="./读书笔记---AI System/CleanShot 2025-04-07 at 11.58.11@2x.png" alt="CleanShot 2025-04-07 at 11.58.11@2x" style="zoom:67%;" />
<p>模型量化还有两种，非对称量化和对称量化。</p>
<img src="./读书笔记---AI System/CleanShot 2025-04-07 at 11.59.47@2x.png" alt="CleanShot 2025-04-07 at 11.59.47@2x" style="zoom:67%;" />
<h4 id="量化">量化</h4>
<blockquote>
<p>将浮点数（如 FP32）映射为整数（如 INT8、UINT8），以减小模型体积、加速推理。</p>
</blockquote>
<hr>
<h5 id="对称量化（Symmetric-Quantization）">对称量化（Symmetric Quantization）</h5>
<h6 id="概念">概念</h6>
<ul>
<li>假设数据以 0 为中心对称分布</li>
<li>映射到整数范围 <code>[-128, 127]</code>（INT8）</li>
<li><code>zero_point = 0</code></li>
</ul>
<h6 id="公式">公式</h6>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">scale = max_abs / 127<br>zero_point = 0<br>q = round(r / scale)<br></code></pre></td></tr></table></figure>
<p>反量化：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">r ≈ scale * q<br></code></pre></td></tr></table></figure>
<h6 id="示例（实际范围-500-1000-）">示例（实际范围 <code>[-500, 1000]</code>）</h6>
<ol>
<li>取最大绝对值：<code>max_abs = 1000</code></li>
<li>映射区间设为 <code>[-1000, 1000]</code></li>
<li>计算：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">scale = 1000 / 127 ≈ 7.874<br>zero_point = 0<br></code></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>实际值 r</th>
<th>量化值 q</th>
</tr>
</thead>
<tbody>
<tr>
<td>-1000</td>
<td>-127</td>
</tr>
<tr>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1000</td>
<td>127</td>
</tr>
</tbody>
</table>
<hr>
<h5 id="非对称量化（Asymmetric-Quantization）">非对称量化（Asymmetric Quantization）</h5>
<h6 id="概念-2">概念</h6>
<ul>
<li>适配非对称分布（如 ReLU 输出）</li>
<li>映射到 <code>[0, 255]</code>（UINT8）</li>
<li>需要 <code>zero_point ≠ 0</code></li>
</ul>
<h6 id="公式-2">公式</h6>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">scale = (r_max - r_min) / 255<br>zero_point = round(-r_min / scale)<br>q = round(r / scale + zero_point)<br></code></pre></td></tr></table></figure>
<p>反量化：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">r ≈ scale * (q - zero_point)<br></code></pre></td></tr></table></figure>
<h6 id="示例（实际范围-500-1000-）-2">示例（实际范围 <code>[-500, 1000]</code>）</h6>
<ol>
<li>不需要扩展区间，直接使用 <code>[-500, 1000]</code></li>
<li>计算：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">scale = (1000 - (-500)) / 255 ≈ 5.882<br>zero_point = round(500 / 5.882) ≈ 85<br></code></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>实际值 r</th>
<th>量化值 q</th>
</tr>
</thead>
<tbody>
<tr>
<td>-500</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>85</td>
</tr>
<tr>
<td>1000</td>
<td>255</td>
</tr>
</tbody>
</table>
<hr>
<h5 id="对比总结表">对比总结表</h5>
<table>
<thead>
<tr>
<th>特性</th>
<th>对称量化</th>
<th>非对称量化</th>
</tr>
</thead>
<tbody>
<tr>
<td>是否以 0 为中心</td>
<td>✅ 是</td>
<td>❌ 否</td>
</tr>
<tr>
<td>是否有 zero_point</td>
<td>❌ 无（固定为 0）</td>
<td>✅ 有</td>
</tr>
<tr>
<td>整数范围</td>
<td><code>[-128, 127]</code> (INT8)</td>
<td><code>[0, 255]</code> (UINT8)</td>
</tr>
<tr>
<td>精度表现</td>
<td>中等</td>
<td>更好（适合偏移数据）</td>
</tr>
<tr>
<td>计算效率</td>
<td>高（无需偏移）</td>
<td>稍慢（多一个偏移量）</td>
</tr>
<tr>
<td>常见应用</td>
<td>权重量化</td>
<td>激活量化</td>
</tr>
</tbody>
</table>
<hr>
<h5 id="一句话总结">一句话总结</h5>
<ul>
<li><strong>对称量化</strong>：适合数据以 0 为中心的情况，速度快，常用于权重。</li>
<li><strong>非对称量化</strong>：适合分布偏移的数据（如激活值），精度更高但计算更复杂。</li>
</ul>
<p>当然还有别的量化方法，书里没有具体介绍，只稍微提了一下。</p>
<h4 id="剪枝">剪枝</h4>
<img src="./读书笔记---AI System/CleanShot 2025-04-07 at 13.30.57@2x.png" alt="CleanShot 2025-04-07 at 13.30.57@2x" style="zoom:67%;" />
<h4 id="卷积层计算原理总结">卷积层计算原理总结</h4>
<h5 id="卷积层参数量计算公式">卷积层参数量计算公式</h5>
<p>对于一个输入大小为 W × H × Ci 的特征图：</p>
<ul>
<li>卷积核大小为 k × k</li>
<li>输入通道数为 Ci</li>
<li>输出通道数为 Co</li>
</ul>
<p>该卷积层的参数总量为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">Params = (k × k × Ci + 1) × Co<br></code></pre></td></tr></table></figure>
<p>说明：</p>
<ul>
<li>k × k × Ci 是每个输出通道的权重数量（每个输入通道都有独立的一套权重）</li>
<li>+1 表示 bias（每个输出通道对应一个偏置项）</li>
<li>× Co 表示有 Co 个输出通道</li>
</ul>
<p>每个卷积核是一个三维体积（k × k × Ci），负责融合多个输入通道的信息。</p>
<hr>
<h5 id="每个输出点的计算过程">每个输出点的计算过程</h5>
<p>对于输出特征图中每个位置 (i, j) 和输出通道 co，对应的计算为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">output[i][j][co] = sum_&#123;ci=0&#125;^&#123;Ci-1&#125; <br>conv(input_patch[i][j][ci], weight[co][ci]) + bias[co]<br></code></pre></td></tr></table></figure>
<p>步骤如下：</p>
<ol>
<li>对每个输入通道 ci，取出其上的 k × k 区域 patch。</li>
<li>将该 patch 和该通道对应的卷积核权重做逐元素乘法并求和。</li>
<li>对所有通道的结果加总。</li>
<li>最后加上 bias，得到一个输出标量。</li>
</ol>
<hr>
<h5 id="FLOPs-浮点运算次数计算">FLOPs 浮点运算次数计算</h5>
<p>FLOPs 表示模型中执行的浮点操作数量。</p>
<p>对于上述卷积操作，其 FLOPs 为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">FLOPs = W × H × (k × k × Ci + 1) × Co<br></code></pre></td></tr></table></figure>
<p>说明：</p>
<ul>
<li>每个输出位置需要 k × k × Ci 次乘加（MAC）</li>
<li>+1 表示加上 bias</li>
<li>W × H 表示输出特征图的空间位置数</li>
<li>Co 表示输出通道数量</li>
</ul>
<p>注意：有些库或论文将乘法和加法各算 1 次 FLOP，此时 FLOPs 约为 2 × W × H × k² × Ci × Co</p>
<hr>
<h5 id="总结要点">总结要点</h5>
<ul>
<li>卷积核在每个输入通道上都有独立的权重。</li>
<li>每个输出通道对应一整组输入通道上的卷积核。</li>
<li>卷积计算是“多通道 patch 和权重的加权求和”。</li>
<li>参数量和 FLOPs 都随输入通道数、卷积核大小、输出通道数线性增长。</li>
</ul>
<h4 id="卷积核分解：VGG-与-Inception-方法总结">卷积核分解：VGG 与 Inception 方法总结</h4>
<hr>
<h5 id="一、背景">一、背景</h5>
<p>这其实是一种模型轻量化的方法，VGG 和 Inception 都是在模型设计着手，希望减少内存的使用。</p>
<p>在卷积神经网络中，大卷积核（如 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn><mo>×</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">7 \times 7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">7</span></span></span></span>）具有较大的感受野，但带来更多参数和更高的计算成本。因此，现代网络架构（如 VGG 和 Inception）采用了卷积核分解策略，在保持相似感受野的前提下显著降低参数量和 FLOPs。</p>
<hr>
<h5 id="二、VGG-的分解方式">二、VGG 的分解方式</h5>
<h6 id="1-思路">1. 思路</h6>
<p>使用两个连续的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3 \times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3</span></span></span></span> 卷积层来替代一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span> 卷积层。</p>
<ul>
<li>每个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3 \times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3</span></span></span></span> 卷积感受野是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3</span></span></span></span></li>
<li>两个堆叠后感受野变为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn></mrow><annotation encoding="application/x-tex">5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span></li>
</ul>
<h6 id="2-感受野推导">2. 感受野推导</h6>
<p>假设每层卷积核大小为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">k=3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3</span></span></span></span>，堆叠 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">L=2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span></span></span></span> 层，stride=1，padding=1，则感受野为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mo>=</mo><mn>1</mn><mo>+</mo><mo stretchy="false">(</mo><mi>k</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>×</mo><mi>L</mi><mo>=</mo><mn>1</mn><mo>+</mo><mo stretchy="false">(</mo><mn>3</mn><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>×</mo><mn>2</mn><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">R = 1 + (k - 1) \times L = 1 + (3 - 1) \times 2 = 5
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span></span></p>
<h6 id="3-参数量对比（假设输入输出通道数均为-C）">3. 参数量对比（假设输入输出通道数均为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>）</h6>
<ul>
<li>原始 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span> 卷积参数量为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>25</mn><msup><mi>C</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">25C^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">25</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></li>
<li>两个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3 \times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3</span></span></span></span> 卷积为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>×</mo><mn>9</mn><msup><mi>C</mi><mn>2</mn></msup><mo>=</mo><mn>18</mn><msup><mi>C</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">2 \times 9C^2 = 18C^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">9</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">18</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></li>
<li>相对节省：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>18</mn><mn>25</mn></mfrac><mo>=</mo><mn>72</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{18}{25} = 72\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">25</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">18</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">72%</span></span></span></span></li>
</ul>
<hr>
<h5 id="三、Inception-的分解方式">三、Inception 的分解方式</h5>
<h6 id="1-思路-2">1. 思路</h6>
<p>将二维的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span> 卷积拆解为两个一维卷积：先做垂直方向的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">5 \times 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>，再做水平方向的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">1 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span> 卷积。</p>
<h6 id="2-操作过程">2. 操作过程</h6>
<ul>
<li>第一步：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">5 \times 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 卷积在输入图像上纵向滑动，融合每列中上下 5 个像素的信息</li>
<li>第二步：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">1 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span> 卷积在中间特征图上横向滑动，融合每行左右 5 个像素的信息</li>
<li>最终输出感受野覆盖原图中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span> 区域</li>
</ul>
<h6 id="3-参数量对比（输入输出通道为-C）">3. 参数量对比（输入输出通道为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>）</h6>
<ul>
<li>原始 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span> 卷积参数量为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>25</mn><msup><mi>C</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">25C^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">25</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></li>
<li>分解卷积参数量为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><msup><mi>C</mi><mn>2</mn></msup><mo>+</mo><mn>5</mn><msup><mi>C</mi><mn>2</mn></msup><mo>=</mo><mn>10</mn><msup><mi>C</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">5C^2 + 5C^2 = 10C^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">5</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">10</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></li>
<li>相对节省：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>10</mn><mn>25</mn></mfrac><mo>=</mo><mn>40</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{10}{25} = 40\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">25</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">40%</span></span></span></span></li>
</ul>
<hr>
<h5 id="四、两种分解方式对比总结">四、两种分解方式对比总结</h5>
<table>
<thead>
<tr>
<th>方法</th>
<th>感受野</th>
<th>参数量</th>
<th>相对节省</th>
</tr>
</thead>
<tbody>
<tr>
<td>原始 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span> 卷积</td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span></td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>25</mn><msup><mi>C</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">25C^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">25</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></td>
<td>-</td>
</tr>
<tr>
<td>两个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3 \times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3</span></span></span></span> 卷积</td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span></td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>18</mn><msup><mi>C</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">18C^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">18</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></td>
<td>28%</td>
</tr>
<tr>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>1</mn><mo>+</mo><mn>1</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5 \times 1 + 1 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span> 卷积</td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span></td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn><msup><mi>C</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">10C^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">10</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></td>
<td>60%</td>
</tr>
</tbody>
</table>
<hr>
<h5 id="五、结论与适用场景">五、结论与适用场景</h5>
<ul>
<li>VGG 的堆叠卷积方式简单直接，适用于一般结构的构建与替代</li>
<li>Inception 的分解卷积方式更高效、参数更少，适用于模块化组合（如 Inception 模块）</li>
</ul>
<p>两者都遵循一个核心思想：</p>
<blockquote>
<p>通过卷积核分解，在保持感受野不变的前提下，减少计算量与参数量，从而构建更高效的深度网络结构</p>
</blockquote>
<h4 id="其他模型轻量化方法">其他模型轻量化方法</h4>
<img src="./读书笔记---AI System/CleanShot 2025-04-07 at 15.55.21@2x.png" alt="CleanShot 2025-04-07 at 15.55.21@2x" style="zoom:67%;" />
<p>这个写的还是挺明白的。</p>
<p>后面还讲了讲并行，覆盖的还算比较全面。</p>
<h3 id="关键设计指标">关键设计指标</h3>
<p>前面有一些指标感觉比较重要。</p>
<p>后面计算某个操作是计算受限型还是内存受限型还是比较有意思的。</p>
<p>最后 Roofline 的概念感觉也是经常可以在论文里看到，就计算某个系统的理论极值。</p>
<h3 id="核心计算之矩阵乘">核心计算之矩阵乘</h3>
<p>这里就是怎么把卷积换成矩阵乘法，感觉还比较有意义。</p>
<img src="./读书笔记---AI System/CleanShot 2025-04-08 at 09.40.27.png" alt="CleanShot 2025-04-08 at 09.40.27" style="zoom:80%;" />
<img src="./读书笔记---AI System/CleanShot 2025-04-08 at 09.39.41.png" alt="CleanShot 2025-04-08 at 09.39.41" style="zoom:80%;" />
<p>这个图就很直观</p>
<p>然后就是计算机实现矩阵乘法的一些优化，说实话没太看懂，也没仔细看。</p>
<h3 id="计算之比特位宽">计算之比特位宽</h3>
<p>这个基本讲的就是各种浮点数的标准，比如最标准的单精度浮点数的 32 个 bits 是怎么分配的，这个一般 OS 课应该会详细讲。后面还大概介绍了一下别的新的标准。</p>
<h2 id="AI-芯片基础">AI 芯片基础</h2>
<h3 id="CPU-基础">CPU 基础</h3>
<p>感觉全是各种历史，梦回大一计算机导论。</p>
<p>冯诺依曼结构，电路，各种寄存器。感觉 ECE 的同学主要就是学这些。</p>
<h3 id="CPU-指令集架构">CPU 指令集架构</h3>
<p>这个讲了很多 CISC 和 RISC 的东西。一般 OS 有三节课，感觉基本上就是 OS 第一节课会讲的，看一看就行，还是历史相关的内容比较多。CISC 和 RISC 都是 ISA 的分类，后面还讲了 CPU 并行处理架构。比如什么 SISD 之类的。</p>
<p>里面有几个图还挺好的。</p>
<img src="./读书笔记---AI System/CleanShot 2025-04-11 at 10.27.32@2x.png" alt="CleanShot 2025-04-11 at 10.27.32@2x" style="zoom:80%;" />
<h3 id="CPU-计算本质">CPU 计算本质</h3>
<p>讲了一些参数，讲了一下 CPU，服务器之类的东西这几年来的发展。</p>
<h3 id="CPU-计算时延">CPU 计算时延</h3>
<p>用了一个例子分析了计算时延，基本上大头还是 load data 造成的。</p>
<h3 id="GPU-基础">GPU 基础</h3>
<p>基本上就是 GPU 发展的过程，NVIDIA 占据一大块，比国有个神奇的公司 ATI 从来没听说过，在这里戏份挺足。后面 ATI 被 AMD 收购了，AMD显卡的技术就来自于 ATI。</p>
<h3 id="NPU-基础">NPU 基础</h3>
<p>感觉真正做出来的 NPU 也就只有 Google 的 TPU。</p>
<p>主要就是 DSA（Domain-Specific Architecture）。</p>
<h3 id="超异构计算">超异构计算</h3>
<p>这个说的就是不拘泥于原来的提醒，把 CPU，GPU，TPU 什么的都整合到一个芯片上，用来应对比较复杂的问题。</p>
<p>而且其实就常规的 CPU + GPU 也算是异构计算，但他有两个独立的 memory。</p>
<p>不过我觉得最好的例子还是 Apple 的 M 系列芯片，尤其是 M4，统一内存，然后还有 GPU 核心，还有 CPU核心，还非常成功。</p>
<p>不过 Apple 的 M 系列芯是算异构还是超异构，其实我也不太清楚，毕竟这些都是比较新的概念，但感觉超异构的概念还是再说那种大型的计算中心。</p>
<h2 id="图形处理器-GPU">图形处理器 GPU</h2>
<h3 id="GPU-工作原理">GPU 工作原理</h3>
<p>GPU 里用的内存主要是 <strong>HBM（High Bandwidth Memory，高带宽内存）</strong>，是一种专门为<strong>高性能计算和图形处理器</strong>设计的先进内存技术。</p>
<img src="./读书笔记---AI System/CleanShot 2025-04-12 at 12.27.45.png" alt="CleanShot 2025-04-12 at 12.27.45" style="zoom:80%;" />
<p>这个图很清楚。</p>
<h3 id="为什么-GPU-适用于-AI">为什么 GPU 适用于 AI</h3>
<p>又讲了很长的卷积，甚至还有矩阵计算，稍有重叠。</p>
<p>一个新的概念，tensor core。我的理解基本就是为了更好做矩阵计算的。</p>
<h3 id="GPU-架构与-CUDA-关系">GPU 架构与 CUDA 关系</h3>
<p>我的理解，一个线程就是一个 cuda core。</p>
<h3 id="GPU-架构回顾">GPU 架构回顾</h3>
<p>介绍 NVIDIA 的 GPU 历史了，但不得不说，NVIDIA 那么多显卡种类，那么多架构，一般人还真是都不知道，就知道一个 RTX。</p>
<p>稀疏化矩阵怎么计算的，这里也有稍微讲一下。</p>
<img src="./读书笔记---AI System/CleanShot 2025-04-12 at 19.27.04.png" alt="CleanShot 2025-04-12 at 19.27.04" style="zoom:80%;" />
<p>但大部分还都是各种架构 GPU 的参数，其实挺无聊的。不过确实是能感受到 NVIDIA 的技术重心，最开始基本上就是帮助计算图像的，还有单独的图像处理单元，到最近基本上 all in AI，全都是围绕 AI 去做的产品。</p>
<h2 id="英伟达-GPU-详解">英伟达 GPU 详解</h2>
<p>前面一章已经讲了 GPU，这一章专门讲 Nvidia 的 GPU。</p>
<p>在 Nvidia 的 GPU 架构里，有三种主要核心：CUDA Core、Tensor Core 和 RT Core。</p>
<h3 id="Tensor-Core-基本原理">Tensor Core 基本原理</h3>
<p>这个小节讨论的就是 Tensor Core，又是用卷积来作为讨论，感觉卷积已经不太火了，但是本文很多具体的例子都是卷积相关的，可能当时写的时候 NLP 或者 LLM 还没很火吧。</p>
<p>最开始的处理核心是 Stream Processor（SPs）。</p>
<p>后来有了 Stream Multiprocessor（SMs）。</p>
<p>再后来才有的 CUDA Core，之后 AI 火了，为了加速矩阵运算才有的 Tensor Core。RT Core 则是光追单元，功能也是比较特殊。</p>
<p>之前其实就见到过，卷积操作可以变成矩阵乘法，这个操作叫做 Im2Col。</p>
<p>反正很神奇，我只能说我大概好像看懂具体是怎么操作的里，想法大致是了解的，但是具体的变换计算我也不知道书里写的对不对。</p>
<p>大致讲了一下混和精度训练，大致就是 FP32 的参数，转化为 FP16 进行 Forward，最后更新梯度的时候转回 FP32。</p>
<p>Tensor Core 的一大用处就是混合精度训练，因为混合精度训练一般需要硬件支持。</p>
<h3 id="Tensor-Core-架构演进">Tensor Core 架构演进</h3>
<p>这一章又讲了一点历史，但是还讲了很多芯片架构相关的知识，有很多架构图，还是比较清晰的。</p>
<h3 id="Tensor-Core-深度剖析">Tensor Core 深度剖析</h3>
<p>这个深度讲了 Tensor Core 的设计，非常神奇，他电路直接设计的就是做矩阵乘法，而不是我们正常设计的乘法器和加法器。</p>
<p>总的来说就是在计算的时候把大矩阵切成小矩阵去算，切成小矩阵的时候把数据放到共享内存或者更进一步放到 register 里，给 Tensor Core 里的计算单元去用。</p>
<h3 id="分布式通信与-NVLink">分布式通信与 NVLink</h3>
<p>讲了并行，就是什么 DP，PP，TP 啥的。</p>
<p>讲完并行之后引出了分布式训练，其实并行和分布式训练时联系在一起的。你把模型做切割就是为了放到不同的机器上做并行，你放到不同的机器上就是分布式训练了。</p>
<p>然后还介绍了通讯，硬件上比如说什么 PCIe、NVLink 之类的，但是就只是简单说了下。最后还有 NVLink 和 NVSwitch 每一代的演进。</p>
<p>还有各种通信的抽象类型，底下这个图还是比较清晰的。</p>
<img src="./读书笔记---AI System/CleanShot 2025-04-23 at 10.35.24@2x.png" alt="CleanShot 2025-04-23 at 10.35.24@2x" style="zoom:80%;" />
<h3 id="NVLink-原理剖析">NVLink 原理剖析</h3>
<p>这章提到了两个概念，算存互联和算力互联。这两个方面感觉确实是很重要，很多时候训练的瓶颈都是卡在了通信上，而通信基本上就是在算存与算力之间通信。</p>
<p>最开始的时候只有 PCIe，但很明显 PCIe 速度比较比较慢，然后 Nvidia 就开卡了 NVLink，现在你基本如果想要组一个 Nvidia 的 GPU 集群的话，必要NVLink 或者 NVSwitch，价格也是很感人。</p>
<p>后面有一点技术细节，硬件上基本看不懂，信号传输，冗余什么的还能看懂一点。</p>
<p>最后又讲了一下这个发展历程，感觉发展历程讲了好几次。</p>
<h2 id="国外-AI-芯片">国外 AI 芯片</h2>
<h3 id="谷歌-TPU-历史发展">谷歌 TPU 历史发展</h3>
<p>就讲讲历史，感觉没啥的。</p>
<h3 id="谷歌-TPU-v1-脉动阵列">谷歌 TPU v1 脉动阵列</h3>
<p>这个脉动阵列和 Nvidia 的 tensor core 很像，都是直接一下子算个矩阵乘法。</p>
<img src="./读书笔记---AI System/CleanShot 2025-04-30 at 13.26.50.png" alt="CleanShot 2025-04-30 at 13.26.50" style="zoom:80%;" />
<p>上面这图比较清楚。</p>
<h3 id="谷歌-TPU-v2-训练芯片">谷歌 TPU v2 训练芯片</h3>
<p>V2 我记得是可以进行训练了，v1 是纯推理卡。</p>
<p>然后 V2 加了互联的模块，就更适合连载一起组一个大的集群。</p>
<h3 id="谷歌-TPU-v3-POD-形态">谷歌 TPU v3 POD 形态</h3>
<p>V3 就是 V2 的算力加强版本，没太多架构上的变化，就制程工艺的进步，同样的大小塞的计算单元更多了。</p>
<h3 id="谷歌-TPUv4-与光路交换">谷歌 TPUv4 与光路交换</h3>
<p>TPU v4 用了很久才推出的，更新比较多。</p>
<p>感觉这个架构图比较重要。</p>
<img src="./读书笔记---AI System/CleanShot 2025-04-30 at 16.13.52.png" alt="CleanShot 2025-04-30 at 16.13.52" style="zoom:80%;" />
<p>主要的变化是加了 Sparse Core 这个单元，然后就是在组计算单元的时候用了 3D-Torus。</p>
<p>Sparse Core 感觉就是主要为 NLP 做的，因为 NLP 我们 embedding 之后基本上就是一个很大的稀疏矩阵。</p>
<p>这个 notes 不得不说如果每章都写的话没啥意思，我自己看都没意思，还是写一些有意思的或者我自己的思考吧。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://s-tanley.github.io/blogs">Stanley Zheng</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://s-tanley.github.io/blogs/2025/04/06/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0---AI%20System/">https://s-tanley.github.io/blogs/2025/04/06/读书笔记---AI System/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/blogs/tags/MLSys/">MLSys</a></div><div class="post-share"><div class="social-share" data-image="/blogs/img/MyProfilePicture.JPG" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/blogs/2025/03/28/FasterMoE/" title="Reading Notes for FasterMoE"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">Reading Notes for FasterMoE</div></div><div class="info-2"><div class="info-item-1">Summary Abstract &amp; Introduction &amp;  Background and Challenges 前面又是简单介绍MoE，基本都一样。 这个也是training方向的，说了三个challenges：   dynamic load imbalance 在intro里，叫Dynamic expert selection，就也比较明显，就是每次选的experts不一样。   inefficient synchronous execution mode 在intro里，叫Inefficient synchronous operations，就是expert有dependency，就需要别的worker的data，要等。   congested all-to-all communication 在intro里，叫Mismatch of model design and network topology，感觉他的意思是现在的system只管摆放experts的computation...</div></div></div></a><a class="pagination-related" href="/blogs/2025/04/07/AllReduce%20&amp;%20Bucketing/" title="AllReduce &amp; Bucketing"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">AllReduce & Bucketing</div></div><div class="info-2"><div class="info-item-1">本文主要介绍了 AllReduce 和 Bucketing 分别是什么，和他们之间的联系。 一、AllReduce 是什么？ AllReduce 是分布式训练中的一种集体通信操作， 用于在多个 GPU（worker）之间同步张量（通常是梯度）。 典型流程如下：  每个 GPU 独立计算自己的梯度张量（如 grad）。 所有 GPU 通过 AllReduce 操作，将各自的张量求和/平均，获得全局一致的梯度。 每个 GPU 使用这个同步后的梯度更新模型参数。  AllReduce 是数据并行训练中实现模型同步的关键机制。  二、为什么 AllReduce 会成为性能瓶颈？  模型中参数众多，梯度张量数量也很多。 每个张量如果单独 AllReduce，通信次数极多。 小张量通信无法充分利用带宽，且频繁启动通信带来显著延迟（latency）。   三、Bucketing 是什么？ Bucketing 是一种优化 AllReduce 通信效率的策略， 将多个小张量合并成一个大 “bucket”，再一次性执行 AllReduce。 核心思想：Batch Small Reduces...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/blogs/2025/04/07/AllReduce%20&%20Bucketing/" title="AllReduce &amp; Bucketing"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-07</div><div class="info-item-2">AllReduce &amp; Bucketing</div></div><div class="info-2"><div class="info-item-1">本文主要介绍了 AllReduce 和 Bucketing 分别是什么，和他们之间的联系。 一、AllReduce 是什么？ AllReduce 是分布式训练中的一种集体通信操作， 用于在多个 GPU（worker）之间同步张量（通常是梯度）。 典型流程如下：  每个 GPU 独立计算自己的梯度张量（如 grad）。 所有 GPU 通过 AllReduce 操作，将各自的张量求和/平均，获得全局一致的梯度。 每个 GPU 使用这个同步后的梯度更新模型参数。  AllReduce 是数据并行训练中实现模型同步的关键机制。  二、为什么 AllReduce 会成为性能瓶颈？  模型中参数众多，梯度张量数量也很多。 每个张量如果单独 AllReduce，通信次数极多。 小张量通信无法充分利用带宽，且频繁启动通信带来显著延迟（latency）。   三、Bucketing 是什么？ Bucketing 是一种优化 AllReduce 通信效率的策略， 将多个小张量合并成一个大 “bucket”，再一次性执行 AllReduce。 核心思想：Batch Small Reduces...</div></div></div></a><a class="pagination-related" href="/blogs/2025/04/07/MoE%20%E4%B8%AD%20All-to-All%20%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6/" title="MoE 中 All-to-All 通信机制"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-07</div><div class="info-item-2">MoE 中 All-to-All 通信机制</div></div><div class="info-2"><div class="info-item-1">本文主要介绍了 All-to-All 通信机制，以及为什么需要这个机制。 一、All-to-All 是什么？ 在分布式 Mixture-of-Experts（MoE）模型中，All-to-All 是一种通信操作， 用于在多个 GPU 之间交换 token 和专家（Expert）之间的数据。 每个 GPU 上都有输入 token，而每个 Expert 分布在多个不同的 GPU 上。 Gate 网络决定每个 token 应该由哪些专家处理，因此 token 需要被动态发送到目标 Expert 所在的 GPU。 这正是 All-to-All：每个 GPU 既向其他 GPU 发送数据，也接收来自其他 GPU 的数据。  二、为什么 MoE 模型需要 All-to-All？ 1. Expert 是独立的，但 Token 是全局的  每个 Expert 的参数是本地的，只存在于某个 GPU 上。 但 token 是通过数据并行划分的，分布在所有 GPU 上。 每个 token 的 gate 结果可能指向任意 GPU 上的 Expert。  因此，token 必须被跨设备发送到它所选中的...</div></div></div></a><a class="pagination-related" href="/blogs/2025/03/28/FasterMoE/" title="Reading Notes for FasterMoE"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-28</div><div class="info-item-2">Reading Notes for FasterMoE</div></div><div class="info-2"><div class="info-item-1">Summary Abstract &amp; Introduction &amp;  Background and Challenges 前面又是简单介绍MoE，基本都一样。 这个也是training方向的，说了三个challenges：   dynamic load imbalance 在intro里，叫Dynamic expert selection，就也比较明显，就是每次选的experts不一样。   inefficient synchronous execution mode 在intro里，叫Inefficient synchronous operations，就是expert有dependency，就需要别的worker的data，要等。   congested all-to-all communication 在intro里，叫Mismatch of model design and network topology，感觉他的意思是现在的system只管摆放experts的computation...</div></div></div></a><a class="pagination-related" href="/blogs/2025/05/15/Orca/" title="Reading Notes for Orca"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-15</div><div class="info-item-2">Reading Notes for Orca</div></div><div class="info-2"><div class="info-item-1">This is the reading notes for the ORCA: A Distributed Serving System for Transformer-Based Generative Models. This is an OSDI conference paper from 2022. Almost all the authors come from South Korea, and actually, this is the first time I have read papers written by Koreans. Summary Abstract &amp; Introduction &amp; Background The paper is focused on the inference serving, they point out that the existing system is not good enough for transformer-based models. So, they propose a new method...</div></div></div></a><a class="pagination-related" href="/blogs/2025/06/10/Resource%20I%20have%20for%20MLSys/" title="Resource I Have for MLSys"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-10</div><div class="info-item-2">Resource I Have for MLSys</div></div><div class="info-2"><div class="info-item-1">This is like a guidance page for the resources I know for MLSys, I’ll give a brief introduction to each of them and list the link here. The resources will contain books, papers, and notes I wrote. Books AI System This book is more about the hardware. I think it’s a little bit like for ECE students. I haven’t read it all yet, but I think you can find some useful topics here, such as the introduction to Nvidia GPUs, the Tensor Core, stream multiprocessors, and how the GPU actually do to...</div></div></div></a><a class="pagination-related" href="/blogs/2025/03/27/SmartMoE/" title="Reading Notes for SmartMoE"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-27</div><div class="info-item-2">Reading Notes for SmartMoE</div></div><div class="info-2"><div class="info-item-1">Summary Abstract &amp; Introduction &amp; Background and Motivation Deep neural network（DNN）现在越来越大，除了dense model，就是比较传统的model之外，越来越多的人开始关注sparsely activated model。针对dense model，之前有很多auto-parallelization的方法，但是这些方法对sparsely activated model，比如说MoE架构的模型就没那么好用了。所以他们主要做的就是实现对sparsely activated model做自动并行的分布式训练的方法。 Intro就先说一下来龙去脉，就众所周知，scaling law目前对DNN一直没有失效，所以各家基本上就是一直往上堆参数。但模型变大了就练不动了，所以就要找efficient...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comments</span></div><div class="comment-switch"><span class="first-comment">Giscus</span><span id="switch-btn"></span><span class="second-comment">Utterances</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div><div><div id="utterances-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/blogs/img/MyProfilePicture.JPG" onerror="this.onerror=null;this.src='/blogs/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Stanley Zheng</div><div class="author-info-description">Hi, I am Stanley. I am currently a CS student in the University of Wisconsin-Madison. </div><div class="site-data"><a href="/blogs/archives/"><div class="headline">Articles</div><div class="length-num">46</div></a><a href="/blogs/tags/"><div class="headline">Tags</div><div class="length-num">11</div></a><a href="/blogs/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/S-tanley"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://s-tanley.github.io" target="_blank" title="Homepage"><i class="fas fa-id-badge" style="color: #808080;"></i></a><a class="social-icon" href="https://github.com/S-tanley" target="_blank" title="Github"><i class="fab fa-github" style="color: #808080;"></i></a><a class="social-icon" href="mailto:zbowen936@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #808080;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">AI 系统概述</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">AI 硬件体系结构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#AI-%E8%AE%A1%E7%AE%97%E4%BD%93%E7%B3%BB%E6%A6%82%E8%BF%B0"><span class="toc-number">2.1.</span> <span class="toc-text">AI 计算体系概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#AI-%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%BC%8F"><span class="toc-number">2.1.1.</span> <span class="toc-text">AI 计算模式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8F%E5%8C%96"><span class="toc-number">2.1.1.1.</span> <span class="toc-text">量化</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AF%B9%E7%A7%B0%E9%87%8F%E5%8C%96%EF%BC%88Symmetric-Quantization%EF%BC%89"><span class="toc-number">2.1.1.1.1.</span> <span class="toc-text">对称量化（Symmetric Quantization）</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%A6%82%E5%BF%B5"><span class="toc-number">2.1.1.1.1.1.</span> <span class="toc-text">概念</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%85%AC%E5%BC%8F"><span class="toc-number">2.1.1.1.1.2.</span> <span class="toc-text">公式</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B%EF%BC%88%E5%AE%9E%E9%99%85%E8%8C%83%E5%9B%B4-500-1000-%EF%BC%89"><span class="toc-number">2.1.1.1.1.3.</span> <span class="toc-text">示例（实际范围 [-500, 1000]）</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%9D%9E%E5%AF%B9%E7%A7%B0%E9%87%8F%E5%8C%96%EF%BC%88Asymmetric-Quantization%EF%BC%89"><span class="toc-number">2.1.1.1.2.</span> <span class="toc-text">非对称量化（Asymmetric Quantization）</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%A6%82%E5%BF%B5-2"><span class="toc-number">2.1.1.1.2.1.</span> <span class="toc-text">概念</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%85%AC%E5%BC%8F-2"><span class="toc-number">2.1.1.1.2.2.</span> <span class="toc-text">公式</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B%EF%BC%88%E5%AE%9E%E9%99%85%E8%8C%83%E5%9B%B4-500-1000-%EF%BC%89-2"><span class="toc-number">2.1.1.1.2.3.</span> <span class="toc-text">示例（实际范围 [-500, 1000]）</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E6%80%BB%E7%BB%93%E8%A1%A8"><span class="toc-number">2.1.1.1.3.</span> <span class="toc-text">对比总结表</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%80%E5%8F%A5%E8%AF%9D%E6%80%BB%E7%BB%93"><span class="toc-number">2.1.1.1.4.</span> <span class="toc-text">一句话总结</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%89%AA%E6%9E%9D"><span class="toc-number">2.1.1.2.</span> <span class="toc-text">剪枝</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82%E8%AE%A1%E7%AE%97%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93"><span class="toc-number">2.1.1.3.</span> <span class="toc-text">卷积层计算原理总结</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%8F%82%E6%95%B0%E9%87%8F%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F"><span class="toc-number">2.1.1.3.1.</span> <span class="toc-text">卷积层参数量计算公式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%AF%8F%E4%B8%AA%E8%BE%93%E5%87%BA%E7%82%B9%E7%9A%84%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B"><span class="toc-number">2.1.1.3.2.</span> <span class="toc-text">每个输出点的计算过程</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#FLOPs-%E6%B5%AE%E7%82%B9%E8%BF%90%E7%AE%97%E6%AC%A1%E6%95%B0%E8%AE%A1%E7%AE%97"><span class="toc-number">2.1.1.3.3.</span> <span class="toc-text">FLOPs 浮点运算次数计算</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E8%A6%81%E7%82%B9"><span class="toc-number">2.1.1.3.4.</span> <span class="toc-text">总结要点</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E6%A0%B8%E5%88%86%E8%A7%A3%EF%BC%9AVGG-%E4%B8%8E-Inception-%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93"><span class="toc-number">2.1.1.4.</span> <span class="toc-text">卷积核分解：VGG 与 Inception 方法总结</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E8%83%8C%E6%99%AF"><span class="toc-number">2.1.1.4.1.</span> <span class="toc-text">一、背景</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BA%8C%E3%80%81VGG-%E7%9A%84%E5%88%86%E8%A7%A3%E6%96%B9%E5%BC%8F"><span class="toc-number">2.1.1.4.2.</span> <span class="toc-text">二、VGG 的分解方式</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-%E6%80%9D%E8%B7%AF"><span class="toc-number">2.1.1.4.2.1.</span> <span class="toc-text">1. 思路</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-%E6%84%9F%E5%8F%97%E9%87%8E%E6%8E%A8%E5%AF%BC"><span class="toc-number">2.1.1.4.2.2.</span> <span class="toc-text">2. 感受野推导</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#3-%E5%8F%82%E6%95%B0%E9%87%8F%E5%AF%B9%E6%AF%94%EF%BC%88%E5%81%87%E8%AE%BE%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93%E6%95%B0%E5%9D%87%E4%B8%BA-C%EF%BC%89"><span class="toc-number">2.1.1.4.2.3.</span> <span class="toc-text">3. 参数量对比（假设输入输出通道数均为 CCC）</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%89%E3%80%81Inception-%E7%9A%84%E5%88%86%E8%A7%A3%E6%96%B9%E5%BC%8F"><span class="toc-number">2.1.1.4.3.</span> <span class="toc-text">三、Inception 的分解方式</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-%E6%80%9D%E8%B7%AF-2"><span class="toc-number">2.1.1.4.3.1.</span> <span class="toc-text">1. 思路</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-%E6%93%8D%E4%BD%9C%E8%BF%87%E7%A8%8B"><span class="toc-number">2.1.1.4.3.2.</span> <span class="toc-text">2. 操作过程</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#3-%E5%8F%82%E6%95%B0%E9%87%8F%E5%AF%B9%E6%AF%94%EF%BC%88%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93%E4%B8%BA-C%EF%BC%89"><span class="toc-number">2.1.1.4.3.3.</span> <span class="toc-text">3. 参数量对比（输入输出通道为 CCC）</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E4%B8%A4%E7%A7%8D%E5%88%86%E8%A7%A3%E6%96%B9%E5%BC%8F%E5%AF%B9%E6%AF%94%E6%80%BB%E7%BB%93"><span class="toc-number">2.1.1.4.4.</span> <span class="toc-text">四、两种分解方式对比总结</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E7%BB%93%E8%AE%BA%E4%B8%8E%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">2.1.1.4.5.</span> <span class="toc-text">五、结论与适用场景</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96%E6%96%B9%E6%B3%95"><span class="toc-number">2.1.1.5.</span> <span class="toc-text">其他模型轻量化方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E8%AE%BE%E8%AE%A1%E6%8C%87%E6%A0%87"><span class="toc-number">2.1.2.</span> <span class="toc-text">关键设计指标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E8%AE%A1%E7%AE%97%E4%B9%8B%E7%9F%A9%E9%98%B5%E4%B9%98"><span class="toc-number">2.1.3.</span> <span class="toc-text">核心计算之矩阵乘</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E4%B9%8B%E6%AF%94%E7%89%B9%E4%BD%8D%E5%AE%BD"><span class="toc-number">2.1.4.</span> <span class="toc-text">计算之比特位宽</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AI-%E8%8A%AF%E7%89%87%E5%9F%BA%E7%A1%80"><span class="toc-number">2.2.</span> <span class="toc-text">AI 芯片基础</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CPU-%E5%9F%BA%E7%A1%80"><span class="toc-number">2.2.1.</span> <span class="toc-text">CPU 基础</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CPU-%E6%8C%87%E4%BB%A4%E9%9B%86%E6%9E%B6%E6%9E%84"><span class="toc-number">2.2.2.</span> <span class="toc-text">CPU 指令集架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CPU-%E8%AE%A1%E7%AE%97%E6%9C%AC%E8%B4%A8"><span class="toc-number">2.2.3.</span> <span class="toc-text">CPU 计算本质</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CPU-%E8%AE%A1%E7%AE%97%E6%97%B6%E5%BB%B6"><span class="toc-number">2.2.4.</span> <span class="toc-text">CPU 计算时延</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GPU-%E5%9F%BA%E7%A1%80"><span class="toc-number">2.2.5.</span> <span class="toc-text">GPU 基础</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NPU-%E5%9F%BA%E7%A1%80"><span class="toc-number">2.2.6.</span> <span class="toc-text">NPU 基础</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B6%85%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97"><span class="toc-number">2.2.7.</span> <span class="toc-text">超异构计算</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86%E5%99%A8-GPU"><span class="toc-number">2.3.</span> <span class="toc-text">图形处理器 GPU</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#GPU-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">2.3.1.</span> <span class="toc-text">GPU 工作原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88-GPU-%E9%80%82%E7%94%A8%E4%BA%8E-AI"><span class="toc-number">2.3.2.</span> <span class="toc-text">为什么 GPU 适用于 AI</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GPU-%E6%9E%B6%E6%9E%84%E4%B8%8E-CUDA-%E5%85%B3%E7%B3%BB"><span class="toc-number">2.3.3.</span> <span class="toc-text">GPU 架构与 CUDA 关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GPU-%E6%9E%B6%E6%9E%84%E5%9B%9E%E9%A1%BE"><span class="toc-number">2.3.4.</span> <span class="toc-text">GPU 架构回顾</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8B%B1%E4%BC%9F%E8%BE%BE-GPU-%E8%AF%A6%E8%A7%A3"><span class="toc-number">2.4.</span> <span class="toc-text">英伟达 GPU 详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Tensor-Core-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-number">2.4.1.</span> <span class="toc-text">Tensor Core 基本原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tensor-Core-%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B"><span class="toc-number">2.4.2.</span> <span class="toc-text">Tensor Core 架构演进</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tensor-Core-%E6%B7%B1%E5%BA%A6%E5%89%96%E6%9E%90"><span class="toc-number">2.4.3.</span> <span class="toc-text">Tensor Core 深度剖析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1%E4%B8%8E-NVLink"><span class="toc-number">2.4.4.</span> <span class="toc-text">分布式通信与 NVLink</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NVLink-%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90"><span class="toc-number">2.4.5.</span> <span class="toc-text">NVLink 原理剖析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BD%E5%A4%96-AI-%E8%8A%AF%E7%89%87"><span class="toc-number">2.5.</span> <span class="toc-text">国外 AI 芯片</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%B7%E6%AD%8C-TPU-%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95"><span class="toc-number">2.5.1.</span> <span class="toc-text">谷歌 TPU 历史发展</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%B7%E6%AD%8C-TPU-v1-%E8%84%89%E5%8A%A8%E9%98%B5%E5%88%97"><span class="toc-number">2.5.2.</span> <span class="toc-text">谷歌 TPU v1 脉动阵列</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%B7%E6%AD%8C-TPU-v2-%E8%AE%AD%E7%BB%83%E8%8A%AF%E7%89%87"><span class="toc-number">2.5.3.</span> <span class="toc-text">谷歌 TPU v2 训练芯片</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%B7%E6%AD%8C-TPU-v3-POD-%E5%BD%A2%E6%80%81"><span class="toc-number">2.5.4.</span> <span class="toc-text">谷歌 TPU v3 POD 形态</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%B7%E6%AD%8C-TPUv4-%E4%B8%8E%E5%85%89%E8%B7%AF%E4%BA%A4%E6%8D%A2"><span class="toc-number">2.5.5.</span> <span class="toc-text">谷歌 TPUv4 与光路交换</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blogs/2025/08/21/Using%20Clip%20to%20Music%20Generation/" title="Using Clip to Music Generation">Using Clip to Music Generation</a><time datetime="2025-08-21T05:00:00.000Z" title="Created 2025-08-21 00:00:00">2025-08-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blogs/2025/08/16/%E7%90%86%E8%A7%A3%20Zero-Shot,%20One-Shot,%20%E5%92%8C%20Few-Shot%20%E5%AD%A6%E4%B9%A0/" title="理解 Zero-Shot, One-Shot, 和 Few-Shot 学习">理解 Zero-Shot, One-Shot, 和 Few-Shot 学习</a><time datetime="2025-08-16T05:00:00.000Z" title="Created 2025-08-16 00:00:00">2025-08-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blogs/2025/08/14/Notes---%E8%8B%8F%E5%89%91%E6%9E%97%E5%8D%9A%E5%AE%A2%EF%BC%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%EF%BC%89/" title="Notes---苏剑林博客（词向量与Embedding技术）">Notes---苏剑林博客（词向量与Embedding技术）</a><time datetime="2025-08-14T05:00:00.000Z" title="Created 2025-08-14 00:00:00">2025-08-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blogs/2025/08/11/Notes---%E8%8B%8F%E5%89%91%E6%9E%97%E5%8D%9A%E5%AE%A2%EF%BC%88%E8%AF%8D%E5%90%91%E9%87%8F%E4%B8%8EEmbedding%E6%8A%80%E6%9C%AF%EF%BC%89/" title="Notes---苏剑林博客（神经网络与深度学习基础）">Notes---苏剑林博客（神经网络与深度学习基础）</a><time datetime="2025-08-11T05:00:00.000Z" title="Created 2025-08-11 00:00:00">2025-08-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blogs/2025/08/05/%E5%A4%9A%E6%A8%A1%E6%80%81%E4%B8%AD%E7%9A%84%20Single%20String%20%E4%B8%8E%20Two%20String/" title="多模态中的 Single String 与 Two String">多模态中的 Single String 与 Two String</a><time datetime="2025-08-05T05:00:00.000Z" title="Created 2025-08-05 00:00:00">2025-08-05</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Stanley Zheng</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll to Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/blogs/js/utils.js"></script><script src="/blogs/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (false) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = {"data-mapping":"pathname","data-input-position":"top","data-reactions-enabled":1,"data-strict":1}

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'S-tanley/blogs',
      'data-repo-id': 'R_kgDOOPJb6Q',
      'data-category-id': 'DIC_kwDOOPJb6c4CohlA',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null
  const getUtterancesTheme = theme => theme === 'dark' ? 'photon-dark' : 'github-light'

  const loadUtterances = (el = document, key) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyUtterances = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const config = {
      src: 'https://utteranc.es/client.js',
      repo: 'S-tanley/blogs',
      theme: getUtterancesTheme(document.documentElement.getAttribute('data-theme')),
      crossorigin: 'anonymous',
      async: true,
      ...option,
      'issue-term': isShuoshuo ? key : (option && option['issue-term']) || 'pathname'
    }

    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => ele.setAttribute(key, value))
    el.querySelector('#utterances-wrap').appendChild(ele)
  }

  const changeUtterancesTheme = theme => {
    const iframe = document.querySelector('#utterances-wrap iframe')
    if (iframe) {
      const message = {
        type: 'set-theme',
        theme: getUtterancesTheme(theme)
      };
      iframe.contentWindow.postMessage(message, 'https://utteranc.es')
    }
  }

  btf.addGlobalFn('themeChange', changeUtterancesTheme, 'utterances')

  if (isShuoshuo) {
    'Giscus' === 'Utterances'
      ? window.shuoshuoComment = { loadComment: loadUtterances }
      : window.loadOtherComment = loadUtterances
    return
  }
  
  if ('Giscus' === 'Utterances' || !false) {
    if (false) btf.loadComment(document.getElementById('utterances-wrap'), loadUtterances)
    else loadUtterances()
  } else {
    window.loadOtherComment = loadUtterances
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/blogs/js/search/local-search.js"></script></div></div></body></html>