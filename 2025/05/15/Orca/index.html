<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Reading Notes for Orca | Stanley's Blog</title><meta name="author" content="Stanley Zheng"><meta name="copyright" content="Stanley Zheng"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="This is the reading notes for the ORCA: A Distributed Serving System for Transformer-Based Generative Models. This is an OSDI conference paper from 2022. Almost all the authors come from South Korea,">
<meta property="og:type" content="article">
<meta property="og:title" content="Reading Notes for Orca">
<meta property="og:url" content="https://s-tanley.github.io/blogs/2025/05/15/Orca/index.html">
<meta property="og:site_name" content="Stanley&#39;s Blog">
<meta property="og:description" content="This is the reading notes for the ORCA: A Distributed Serving System for Transformer-Based Generative Models. This is an OSDI conference paper from 2022. Almost all the authors come from South Korea,">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s-tanley.github.io/blogs/img/MyProfilePicture.JPG">
<meta property="article:published_time" content="2025-05-15T05:00:00.000Z">
<meta property="article:modified_time" content="2025-06-08T14:18:09.255Z">
<meta property="article:author" content="Stanley Zheng">
<meta property="article:tag" content="MLSys">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s-tanley.github.io/blogs/img/MyProfilePicture.JPG"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Reading Notes for Orca",
  "url": "https://s-tanley.github.io/blogs/2025/05/15/Orca/",
  "image": "https://s-tanley.github.io/blogs/img/MyProfilePicture.JPG",
  "datePublished": "2025-05-15T05:00:00.000Z",
  "dateModified": "2025-06-08T14:18:09.255Z",
  "author": [
    {
      "@type": "Person",
      "name": "Stanley Zheng",
      "url": "https://s-tanley.github.io/blogs/"
    }
  ]
}</script><link rel="shortcut icon" href="/blogs/img/favicon.png"><link rel="canonical" href="https://s-tanley.github.io/blogs/2025/05/15/Orca/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/blogs/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/blogs/',
  algolia: undefined,
  localSearch: {"path":"/blogs/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"No results found for: ${query}","hits_stats":"${hits} articles found"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Reading Notes for Orca',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/blogs/img/MyProfilePicture.JPG" onerror="this.onerror=null;this.src='/blogs/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/blogs/archives/"><div class="headline">Articles</div><div class="length-num">55</div></a><a href="/blogs/tags/"><div class="headline">Tags</div><div class="length-num">15</div></a><a href="/blogs/categories/"><div class="headline">Categories</div><div class="length-num">8</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="https://s-tanley.github.io"><i class="fa-fw fas fa-id-badge"></i><span> Stanley Zheng</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/blogs/"><img class="site-icon" src="/blogs/img/MyProfilePicture.JPG" alt="Logo"><span class="site-name">Stanley's Blog</span></a><a class="nav-page-title" href="/blogs/"><span class="site-name">Reading Notes for Orca</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="https://s-tanley.github.io"><i class="fa-fw fas fa-id-badge"></i><span> Stanley Zheng</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/blogs/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Reading Notes for Orca</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-05-15T05:00:00.000Z" title="Created 2025-05-15 00:00:00">2025-05-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-06-08T14:18:09.255Z" title="Updated 2025-06-08 09:18:09">2025-06-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/blogs/categories/Reading-Paper/">Reading Paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>This is the reading notes for the <em>ORCA: A Distributed Serving System for Transformer-Based Generative Models</em>. This is an OSDI conference paper from 2022. Almost all the authors come from South Korea, and actually, this is the first time I have read papers written by Koreans.</p>
<h1>Summary</h1>
<h2 id="Abstract-Introduction-Background">Abstract &amp; Introduction &amp; Background</h2>
<p>The paper is focused on the inference serving, they point out that the existing system is not good enough for transformer-based models. So, they propose a new method called <strong>iteration-level scheduling</strong> and create a distributed system called <strong>ORCA</strong>.</p>
<p>Besides the scheduling thing, they also introduced a new batching method to fit with their scheduling method, which is called <strong>selective batching</strong>.</p>
<p>The background information they give is kind of detailed. The first part is about the transformer-based models, the second part is about the existing serving system.</p>
<img src="./Orca/CleanShot 2025-05-25 at 14.20.44@2x.png" alt="CleanShot 2025-05-25 at 14.20.44@2x" style="zoom:80%;" />
<p>The Figure 1(a) actually brings me some confusion, and I talked about it in Thoughts &gt; About Figure 1.</p>
<p>The background information do not have too much to talk about.</p>
<p>There are also two figures about exising inference system.</p>
<img src="./Orca/CleanShot 2025-05-25 at 14.35.46@2x.png" alt="CleanShot 2025-05-25 at 14.35.46@2x" style="zoom:35%;" />
<img src="./Orca/CleanShot 2025-05-25 at 14.36.19@2x.png" alt="CleanShot 2025-05-25 at 14.36.19@2x" style="zoom:35%;" />
<p>Figure 2 is how the existing serving system work, and the Figure 3 is why the current serving system oot good enough. The figure is actually kind of clear.</p>
<p>Basically, we just combine requests in to a batch, the send the batch to the model, and after all the requests meet the end, we send them back. Some request may need more iteration, but the other requests can only wait. This is what the authors want to improve.</p>
<h2 id="Challenges-and-Proposed-Solutions">Challenges and Proposed Solutions</h2>
<p>Just two challenges and two corresponding solutions.</p>
<p>First about schedling and second about batching.</p>
<img src="./Orca/CleanShot 2025-05-25 at 14.44.21@2x.png" alt="CleanShot 2025-05-25 at 14.44.21@2x" style="zoom:35%;" />
<p>They want for each iteration, we can choose the requests, so they create a request pool. Every iteration, they choose enough requests from the pool to make up a batch, and after only one iteration, the model sends the output back to the pool. The requests that are done can be sent back to the clients, and new requests can just be put in the pool.</p>
<img src="./Orca/CleanShot 2025-05-26 at 11.28.58@2x.png" alt="CleanShot 2025-05-26 at 11.28.58@2x" style="zoom:33%;" />
<p>The second thing they do is the selective batching, just like Figure 5 shows above. The basic idea is simple, but there are some details I am confused about. I write them in Thoughts &gt; Confusion &gt; About batching.</p>
<h2 id="ORCA-Design-Implementation">ORCA Design &amp; Implementation</h2>
<p>The ORCA design basically contains two things: one is how we place our model on the GPUs, and the other one is what is the detail of the scheduling.</p>
<img src="./Orca/CleanShot 2025-05-26 at 22.31.56@2x.png" alt="CleanShot 2025-05-26 at 22.31.56@2x" style="zoom:33%;" />
<p>The Figure 6 and 7 introduce how ORCA places the model on GPUs and what parallelization strategy ORCA uses. About parallelism, there are so many different terms about this, but they all represent the same thing.</p>
<img src="./Orca/CleanShot 2025-05-27 at 11.19.42@2x.png" alt="CleanShot 2025-05-27 at 11.19.42@2x" style="zoom:33%;" />
<p>Here, for ORCA, every intra-layer will be set as one node, just like Figure 7 shows. Itâ€™s very clear, not like some other papers, very blurry about what a â€œworkerâ€ or â€œnodeâ€ actually refers to.</p>
<p>For the scheduling algorithm, itâ€™s just very detailed, and thereâ€™s no point I talking here. I have some questions about this, and write them in Thoughts &gt; Confusion &gt; About the scheduling algorithms.</p>
<p>The implementation is very short and do not have too much to talk about.</p>
<h2 id="Evaluation-Related-Work-and-Discussion-Conclusion">Evaluation &amp; Related Work and Discussion &amp; Conclusion</h2>
<p>The evaluation is just you set up a baseline and compare it with different setups, and show that your results are great.</p>
<h1>Thoughts</h1>
<p>The paper is kind of old, I think nowadays the support for the LLM inference is very sophisticated. I know two mainstream open-source projects focus on this area: vLLm and SGLang. I actually know some developers of SGLang. However, in this paper, none of them is mentioned ğŸ˜‚. I think this is because the paper is kind of old, and for the framework it mentions, I actually have no idea.</p>
<h2 id="Confusion">Confusion</h2>
<h3 id="About-Figure-1">About Figure 1</h3>
<p>Figure 1(a) was initially a little confusing for me, as it seemed that in the increment phase, we only needed the output from the last iteration. However, what I remember about how the transformer works is that you add the last iterationâ€™s output to your last iterationâ€™s input. Like in the initial phase, your input is â€œI think itâ€, the output is â€œisâ€, then the next iterationâ€™s input will be â€œI think it isâ€ and so on. If you read some other papers or some other blogs about the transformer, youâ€™ll see some figures drawn in this way.</p>
<p>I think this is about two different ways to express the model. Each iteration definitely uses the information of the previous iterationâ€™s input, but in this paper, the author may think this information is already in our K/V cache or K/V manager. Itâ€™s like not purely input, so they just ignore these. However, I think the most plausible answer to me is that omitting the previous input makes it easy to draw good figuresğŸ˜‚.</p>
<p>This is actually related to another topic, which is â€œwhy in an inference system, we only need to store K/V?â€ There is a <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/23553666052">blog</a> that talks about this issue.</p>
<h3 id="About-batching">About batching</h3>
<h4 id="How-to-batch-requests-together">How to batch requests together</h4>
<p>In this paper, it says that if we satisfy some strict conditions, we can batch different requests together, and I just a little bit confused about that, since for me it seems that there is no way we can do the attention process together.</p>
<h4 id="About-Figure-5">About Figure 5</h4>
<p>I just donâ€™t know why the hidden dimension becomes 3H.</p>
<h3 id="About-the-scheduling-algorithms">About the scheduling algorithms</h3>
<h4 id="first-come-first-served-FCFS">first-come-first-served (FCFS)</h4>
<p>They mention that they make sure that the previous come requests must have greater or equal iteration times than the later requests. However, the detail is omitted, I just wonder how they do this, like sort the request pool every iteration? Just wondering.</p>
<h4 id="max-tokens-attribute"><em>max_tokens</em> attribute</h4>
<p>This is a very important attribute, but they do not state how they get this attribute. It seems that they just know the maximum output length of each requests from nowhere.</p>
<h2 id="Ideas">Ideas</h2>
<h3 id="About-the-iteration-level-scheduling">About the &quot;iteration level scheduling &quot;</h3>
<p>They basically run one iteration of work for a request, then check its status, managing all these requests in a central pool. This â€œiterate once, check onceâ€ model is efficient in some ways, but it sparked a thought: could we make it even smarter?</p>
<p>What if we could get a rough idea, right at the start, of how many iterations a particular request might need to finish? Maybe a small, lightweight predictive model â€“ something like a mini neural network â€“ could look at a requestâ€™s characteristics and make an educated guess. It could flag some as likely â€œquick winsâ€ and others as â€œlonger hauls.â€</p>
<p>If we had that kind of foresight, we could then route requests into different processing pools based on their predicted effort. Imagine a pool for tasks expected to finish in just a few iterations, another for medium-length ones, and a third for those predicted to take a significant amount of time. The real tweak would then be how often we â€œcheck inâ€ on the progress of requests in each pool. For the fast pool, frequent checks, similar to Orcaâ€™s current method, would make sense to maintain responsiveness. But for requests in the medium or long-haul pools, we could reduce the check-in frequency considerably. Instead of checking after every single iteration, perhaps weâ€™d check after every K1 iterations for medium tasks, and an even larger K2 iterations for the long ones.</p>
<p>The potential upside here is a reduction in overhead. Constantly checking the status of a long-running task can be wasteful. By being more selective about when we check, especially for tasks we anticipate will take a while, the system could spend more of its resources actually <em>doing</em> the work rather than managing it. This could lead to better throughput for longer jobs without significantly impacting the latency of shorter ones. Naturally, the accuracy of the predictive model and the overhead of managing multiple pools with different check strategies would be key things to figure out, but itâ€™s an intriguing possibility for optimizing such iterative processing systems. Itâ€™s just a thought bubble for now, but an interesting one!</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://s-tanley.github.io/blogs">Stanley Zheng</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://s-tanley.github.io/blogs/2025/05/15/Orca/">https://s-tanley.github.io/blogs/2025/05/15/Orca/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/blogs/tags/MLSys/">MLSys</a></div><div class="post-share"><div class="social-share" data-image="/blogs/img/MyProfilePicture.JPG" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/blogs/2025/05/07/%E7%94%9F%E6%B4%BB%E6%97%A5%E5%BF%97(2025-5-7)/" title="ç”Ÿæ´»æ—¥å¿—(2025-5-7)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">ç”Ÿæ´»æ—¥å¿—(2025-5-7)</div></div><div class="info-2"><div class="info-item-1">Final Week äº†ï¼Œæœ€è¿‘å¯ä»¥è¯´æ˜¯éå¸¸å¿™ç¢Œäº†ã€‚å›å›½çš„æœºç¥¨éƒ½ä¹°å®Œäº†ï¼Œè¦åå°†è¿‘ä¸¤å¤©é£æœºï¼Œæ„Ÿè§‰ä¹Ÿæ˜¯è›®ç¦»è°±çš„ã€‚CS 525 ä¹Ÿè€ƒå®Œäº†ï¼Œæ„Ÿè§‰åº”è¯¥è¿˜è¡Œï¼Œåº”è¯¥å¯ä»¥æ‹¿ Aã€‚CS 475 å’Œ STAT 333 å°±å‰©ä¸€ä¸ªå°¾å·´äº†ï¼Œæ‰€ä»¥åªå‰©ä¸€ä¸ªå¤ä¹  354 äº†ï¼Œå¸Œæœ›é—®é¢˜ä¸å¤§ï¼Œè¿˜æ²¡å¼€å§‹å¤ä¹ ï¼Œç¬‘æ­»äº†ï¼Œæ„Ÿè§‰ä¸œè¥¿è¿˜æ˜¯æŒºå¤šçš„ã€‚ ä¸è¿‡ä»Šå¤©å¿ƒæƒ…è¿˜è›®ä¸é”™çš„ï¼Œæœ‰ç‚¹å¥½æ¶ˆæ¯ã€‚é™¤äº†è¿™äº›è€ƒè¯•éƒ½è¦è€ƒå®Œäº†ï¼Œæˆ‘éå¸¸ä¹…ä¹‹å‰ç”³è¯·çš„æš‘æœŸçš„çº¿ä¸Š TA å®ä¹ ä¹Ÿç»ˆäºæœ‰æ¶ˆæ¯äº†ï¼Œè¿˜ä»¥ä¸ºç›´æ¥æ— äº†ï¼Œç°åœ¨è‡³å°‘æ˜¯ç¬¬ä¸€å€™é€‰äººäº†ã€‚MBZUAI ä¹Ÿç»ˆäºå›å¤æˆ‘äº†ä¸€ä¸ªé‚®ä»¶ï¼Œè¯´æ˜ä¸€åˆ‡åº”è¯¥éƒ½è¿˜åœ¨ in processï¼Œä½†æ˜¯å¿« 20 å¤©æ‰å›ä¹Ÿæ˜¯æ€ªç¦»è°±çš„ã€‚CS 354 çš„ PM ä¹Ÿé¢è¯•å®Œäº†ï¼Œæ•´æ•´é¢è¯•äº†ä¸€ä¸ªå°æ—¶ï¼Œä¹Ÿæ˜¯æ¯”è¾ƒæŠ½è±¡äº†ï¼Œæˆ‘è®°å¾—è¿™ä¸ªæ—¶é—´ä¹Ÿæ˜¯æœ€åä¸€ä¸ªå¯é€‰çš„æ—¶é—´æ®µï¼Œå¯èƒ½ä¼šå¾ˆå¿«å‡ºç»“æœå§ï¼Œè·Ÿ instructor è¿˜æ˜¯æŒºç†Ÿçš„ï¼Œå¸Œæœ›èƒ½æœ‰å¥½çš„ç»“æœğŸ™ã€‚ åŠ æ²¹äº†ï¼Œä¹Ÿä¸çŸ¥é“ä¸€å¤©å¤Ÿä¸å¤Ÿå¤ä¹ çš„ï¼Œæ„Ÿè§‰å¤Ÿå‘›å•Šå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆï¼Œåˆè¦ç„¦è™‘äº†ï¼Œæ¯•ç«Ÿä¸€ä¸ª quiz å°±èƒ½å†™å¾ˆä¹…ã€‚ æœ€è¿‘è¿˜ä¸€ç›´åœ¨çœ‹ç»„ nas æˆ–è€…ç»„ GPUï¼Œå›å®¶ä¹‹åæ‰“ç®—å…ˆæŠŠæˆ‘çš„ Mac mini å°ä¸»æœºç”¨ä¸Šï¼Œç»„ä¸€ä¸ª nas...</div></div></div></a><a class="pagination-related" href="/blogs/2025/05/16/caffeinate%20%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/" title="Mac å¥½ç”¨çš„å‘½ä»¤è¡Œå·¥å…·æ€»ç»“"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">Mac å¥½ç”¨çš„å‘½ä»¤è¡Œå·¥å…·æ€»ç»“</div></div><div class="info-2"><div class="info-item-1">æŠŠä¸€äº›å¯èƒ½ç”¨åˆ°çš„æ¯”è¾ƒå¥½ç”¨çš„å·¥å…·æ€»ç»“åˆ°äº†è¿™é‡Œã€‚ ä½¿ç”¨ rsync è¿›è¡Œé«˜æ•ˆæ–‡ä»¶åŒæ­¥ä¸æ¢å¤ï¼ˆmacOSï¼‰ rsync æ˜¯ macOS å’Œ Linux ç³»ç»Ÿä¸­å¸¸ç”¨çš„å‘½ä»¤è¡Œæ–‡ä»¶åŒæ­¥å·¥å…·ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ ã€å¢é‡å¤åˆ¶ã€æ’é™¤æ–‡ä»¶ç­‰åŠŸèƒ½ï¼Œéå¸¸é€‚åˆæ‹·è´å¤§æ–‡ä»¶æˆ–è¿›è¡Œæ•°æ®è¿ç§»ã€‚  ä¸€ã€åŸºæœ¬è¯­æ³• rsync [é€‰é¡¹] æºè·¯å¾„ ç›®æ ‡è·¯å¾„ æºè·¯å¾„å’Œç›®æ ‡è·¯å¾„éƒ½å¯ä»¥æ˜¯æœ¬åœ°è·¯å¾„æˆ–è¿œç¨‹è·¯å¾„ï¼ˆä½¿ç”¨ SSHï¼‰ã€‚æ‹·è´è·¯å¾„æ—¶æ³¨æ„ / çš„ä½¿ç”¨å½±å“ç»“æ„ï¼Œè¯¦è§åæ–‡ã€‚ äºŒã€å¸¸ç”¨é€‰é¡¹è¯´æ˜    é€‰é¡¹ å«ä¹‰     -a å½’æ¡£æ¨¡å¼ï¼ˆä¿ç•™æƒé™ã€æ—¶é—´æˆ³ã€ç¬¦å·é“¾æ¥ç­‰ï¼‰   -v è¾“å‡ºè¯¦ç»†ä¿¡æ¯ï¼ˆverboseï¼‰   -h ä»¥äººç±»å¯è¯»çš„æ–¹å¼æ˜¾ç¤ºå¤§å°ï¼ˆå¦‚ 1Kã€20Mï¼‰   â€“progress æ˜¾ç¤ºæ¯ä¸ªæ–‡ä»¶çš„å¤åˆ¶è¿›åº¦   â€“dry-run é¢„æ¼”å‘½ä»¤ä½†ä¸æ‰§è¡Œæ“ä½œï¼Œé€‚åˆæ‹·è´å‰æŸ¥çœ‹å°†ä¼šåšä»€ä¹ˆ   â€“delete åˆ é™¤ç›®æ ‡è·¯å¾„ä¸­ï¼Œæºè·¯å¾„ä¸­å·²ä¸å­˜åœ¨çš„æ–‡ä»¶ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰   â€“update åªå¤åˆ¶æºè·¯å¾„ä¸­æ¯”ç›®æ ‡è·¯å¾„æ›´æ–°çš„æ–‡ä»¶   â€“exclude æ’é™¤æŸäº›æ–‡ä»¶æˆ–ç›®å½•ï¼Œä¾‹å¦‚ .DS_Store    ä¸‰ã€è·¯å¾„æœ«å°¾ / çš„å«ä¹‰  ä¸åŠ ...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/blogs/2025/04/07/AllReduce%20&%20Bucketing/" title="AllReduce &amp; Bucketing"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-07</div><div class="info-item-2">AllReduce &amp; Bucketing</div></div><div class="info-2"><div class="info-item-1">æœ¬æ–‡ä¸»è¦ä»‹ç»äº† AllReduce å’Œ Bucketing åˆ†åˆ«æ˜¯ä»€ä¹ˆï¼Œå’Œä»–ä»¬ä¹‹é—´çš„è”ç³»ã€‚ ä¸€ã€AllReduce æ˜¯ä»€ä¹ˆï¼Ÿ AllReduce æ˜¯åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„ä¸€ç§é›†ä½“é€šä¿¡æ“ä½œï¼Œ ç”¨äºåœ¨å¤šä¸ª GPUï¼ˆworkerï¼‰ä¹‹é—´åŒæ­¥å¼ é‡ï¼ˆé€šå¸¸æ˜¯æ¢¯åº¦ï¼‰ã€‚ å…¸å‹æµç¨‹å¦‚ä¸‹ï¼š  æ¯ä¸ª GPU ç‹¬ç«‹è®¡ç®—è‡ªå·±çš„æ¢¯åº¦å¼ é‡ï¼ˆå¦‚ gradï¼‰ã€‚ æ‰€æœ‰ GPU é€šè¿‡ AllReduce æ“ä½œï¼Œå°†å„è‡ªçš„å¼ é‡æ±‚å’Œ/å¹³å‡ï¼Œè·å¾—å…¨å±€ä¸€è‡´çš„æ¢¯åº¦ã€‚ æ¯ä¸ª GPU ä½¿ç”¨è¿™ä¸ªåŒæ­¥åçš„æ¢¯åº¦æ›´æ–°æ¨¡å‹å‚æ•°ã€‚  AllReduce æ˜¯æ•°æ®å¹¶è¡Œè®­ç»ƒä¸­å®ç°æ¨¡å‹åŒæ­¥çš„å…³é”®æœºåˆ¶ã€‚  äºŒã€ä¸ºä»€ä¹ˆ AllReduce ä¼šæˆä¸ºæ€§èƒ½ç“¶é¢ˆï¼Ÿ  æ¨¡å‹ä¸­å‚æ•°ä¼—å¤šï¼Œæ¢¯åº¦å¼ é‡æ•°é‡ä¹Ÿå¾ˆå¤šã€‚ æ¯ä¸ªå¼ é‡å¦‚æœå•ç‹¬ AllReduceï¼Œé€šä¿¡æ¬¡æ•°æå¤šã€‚ å°å¼ é‡é€šä¿¡æ— æ³•å……åˆ†åˆ©ç”¨å¸¦å®½ï¼Œä¸”é¢‘ç¹å¯åŠ¨é€šä¿¡å¸¦æ¥æ˜¾è‘—å»¶è¿Ÿï¼ˆlatencyï¼‰ã€‚   ä¸‰ã€Bucketing æ˜¯ä»€ä¹ˆï¼Ÿ Bucketing æ˜¯ä¸€ç§ä¼˜åŒ– AllReduce é€šä¿¡æ•ˆç‡çš„ç­–ç•¥ï¼Œ å°†å¤šä¸ªå°å¼ é‡åˆå¹¶æˆä¸€ä¸ªå¤§ â€œbucketâ€ï¼Œå†ä¸€æ¬¡æ€§æ‰§è¡Œ AllReduceã€‚ æ ¸å¿ƒæ€æƒ³ï¼šBatch Small Reduces...</div></div></div></a><a class="pagination-related" href="/blogs/2025/03/28/FasterMoE/" title="Reading Notes for FasterMoE"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-28</div><div class="info-item-2">Reading Notes for FasterMoE</div></div><div class="info-2"><div class="info-item-1">Summary Abstract &amp; Introduction &amp;  Background and Challenges å‰é¢åˆæ˜¯ç®€å•ä»‹ç»MoEï¼ŒåŸºæœ¬éƒ½ä¸€æ ·ã€‚ è¿™ä¸ªä¹Ÿæ˜¯trainingæ–¹å‘çš„ï¼Œè¯´äº†ä¸‰ä¸ªchallengesï¼š   dynamic load imbalance åœ¨introé‡Œï¼Œå«Dynamic expert selectionï¼Œå°±ä¹Ÿæ¯”è¾ƒæ˜æ˜¾ï¼Œå°±æ˜¯æ¯æ¬¡é€‰çš„expertsä¸ä¸€æ ·ã€‚   inefficient synchronous execution mode åœ¨introé‡Œï¼Œå«Inefficient synchronous operationsï¼Œå°±æ˜¯expertæœ‰dependencyï¼Œå°±éœ€è¦åˆ«çš„workerçš„dataï¼Œè¦ç­‰ã€‚   congested all-to-all communication åœ¨introé‡Œï¼Œå«Mismatch of model design and network topologyï¼Œæ„Ÿè§‰ä»–çš„æ„æ€æ˜¯ç°åœ¨çš„systemåªç®¡æ‘†æ”¾expertsçš„computation...</div></div></div></a><a class="pagination-related" href="/blogs/2025/04/07/MoE%20%E4%B8%AD%20All-to-All%20%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6/" title="MoE ä¸­ All-to-All é€šä¿¡æœºåˆ¶"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-07</div><div class="info-item-2">MoE ä¸­ All-to-All é€šä¿¡æœºåˆ¶</div></div><div class="info-2"><div class="info-item-1">æœ¬æ–‡ä¸»è¦ä»‹ç»äº† All-to-All é€šä¿¡æœºåˆ¶ï¼Œä»¥åŠä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªæœºåˆ¶ã€‚ ä¸€ã€All-to-All æ˜¯ä»€ä¹ˆï¼Ÿ åœ¨åˆ†å¸ƒå¼ Mixture-of-Expertsï¼ˆMoEï¼‰æ¨¡å‹ä¸­ï¼ŒAll-to-All æ˜¯ä¸€ç§é€šä¿¡æ“ä½œï¼Œ ç”¨äºåœ¨å¤šä¸ª GPU ä¹‹é—´äº¤æ¢ token å’Œä¸“å®¶ï¼ˆExpertï¼‰ä¹‹é—´çš„æ•°æ®ã€‚ æ¯ä¸ª GPU ä¸Šéƒ½æœ‰è¾“å…¥ tokenï¼Œè€Œæ¯ä¸ª Expert åˆ†å¸ƒåœ¨å¤šä¸ªä¸åŒçš„ GPU ä¸Šã€‚ Gate ç½‘ç»œå†³å®šæ¯ä¸ª token åº”è¯¥ç”±å“ªäº›ä¸“å®¶å¤„ç†ï¼Œå› æ­¤ token éœ€è¦è¢«åŠ¨æ€å‘é€åˆ°ç›®æ ‡ Expert æ‰€åœ¨çš„ GPUã€‚ è¿™æ­£æ˜¯ All-to-Allï¼šæ¯ä¸ª GPU æ—¢å‘å…¶ä»– GPU å‘é€æ•°æ®ï¼Œä¹Ÿæ¥æ”¶æ¥è‡ªå…¶ä»– GPU çš„æ•°æ®ã€‚  äºŒã€ä¸ºä»€ä¹ˆ MoE æ¨¡å‹éœ€è¦ All-to-Allï¼Ÿ 1. Expert æ˜¯ç‹¬ç«‹çš„ï¼Œä½† Token æ˜¯å…¨å±€çš„  æ¯ä¸ª Expert çš„å‚æ•°æ˜¯æœ¬åœ°çš„ï¼Œåªå­˜åœ¨äºæŸä¸ª GPU ä¸Šã€‚ ä½† token æ˜¯é€šè¿‡æ•°æ®å¹¶è¡Œåˆ’åˆ†çš„ï¼Œåˆ†å¸ƒåœ¨æ‰€æœ‰ GPU ä¸Šã€‚ æ¯ä¸ª token çš„ gate ç»“æœå¯èƒ½æŒ‡å‘ä»»æ„ GPU ä¸Šçš„ Expertã€‚  å› æ­¤ï¼Œtoken å¿…é¡»è¢«è·¨è®¾å¤‡å‘é€åˆ°å®ƒæ‰€é€‰ä¸­çš„...</div></div></div></a><a class="pagination-related no-desc" href="/blogs/2025/05/27/SGLang/" title="Reading Notes for SGLang"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-27</div><div class="info-item-2">Reading Notes for SGLang</div></div></div></a><a class="pagination-related" href="/blogs/2025/06/10/Resource%20I%20have%20for%20MLSys/" title="Resource I Have for MLSys"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-10</div><div class="info-item-2">Resource I Have for MLSys</div></div><div class="info-2"><div class="info-item-1">This is like a guidance page for the resources I know for MLSys, Iâ€™ll give a brief introduction to each of them and list the link here. The resources will contain books, papers, and notes I wrote. Books AI System This book is more about the hardware. I think itâ€™s a little bit like for ECE students. I havenâ€™t read it all yet, but I think you can find some useful topics here, such as the introduction to Nvidia GPUs, the Tensor Core, stream multiprocessors, and how the GPU actually do to...</div></div></div></a><a class="pagination-related" href="/blogs/2025/03/27/SmartMoE/" title="Reading Notes for SmartMoE"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-27</div><div class="info-item-2">Reading Notes for SmartMoE</div></div><div class="info-2"><div class="info-item-1">Summary Abstract &amp; Introduction &amp; Background and Motivation Deep neural networkï¼ˆDNNï¼‰ç°åœ¨è¶Šæ¥è¶Šå¤§ï¼Œé™¤äº†dense modelï¼Œå°±æ˜¯æ¯”è¾ƒä¼ ç»Ÿçš„modelä¹‹å¤–ï¼Œè¶Šæ¥è¶Šå¤šçš„äººå¼€å§‹å…³æ³¨sparsely activated modelã€‚é’ˆå¯¹dense modelï¼Œä¹‹å‰æœ‰å¾ˆå¤šauto-parallelizationçš„æ–¹æ³•ï¼Œä½†æ˜¯è¿™äº›æ–¹æ³•å¯¹sparsely activated modelï¼Œæ¯”å¦‚è¯´MoEæ¶æ„çš„æ¨¡å‹å°±æ²¡é‚£ä¹ˆå¥½ç”¨äº†ã€‚æ‰€ä»¥ä»–ä»¬ä¸»è¦åšçš„å°±æ˜¯å®ç°å¯¹sparsely activated modelåšè‡ªåŠ¨å¹¶è¡Œçš„åˆ†å¸ƒå¼è®­ç»ƒçš„æ–¹æ³•ã€‚ Introå°±å…ˆè¯´ä¸€ä¸‹æ¥é¾™å»è„‰ï¼Œå°±ä¼—æ‰€å‘¨çŸ¥ï¼Œscaling lawç›®å‰å¯¹DNNä¸€ç›´æ²¡æœ‰å¤±æ•ˆï¼Œæ‰€ä»¥å„å®¶åŸºæœ¬ä¸Šå°±æ˜¯ä¸€ç›´å¾€ä¸Šå †å‚æ•°ã€‚ä½†æ¨¡å‹å˜å¤§äº†å°±ç»ƒä¸åŠ¨äº†ï¼Œæ‰€ä»¥å°±è¦æ‰¾efficient...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comments</span></div><div class="comment-switch"><span class="first-comment">Giscus</span><span id="switch-btn"></span><span class="second-comment">Utterances</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div><div><div id="utterances-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/blogs/img/MyProfilePicture.JPG" onerror="this.onerror=null;this.src='/blogs/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Stanley Zheng</div><div class="author-info-description">Hi, I am Stanley. I am currently a CS student in the University of Wisconsin-Madison. </div><div class="site-data"><a href="/blogs/archives/"><div class="headline">Articles</div><div class="length-num">55</div></a><a href="/blogs/tags/"><div class="headline">Tags</div><div class="length-num">15</div></a><a href="/blogs/categories/"><div class="headline">Categories</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/S-tanley"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://s-tanley.github.io" target="_blank" title="Homepage"><i class="fas fa-id-badge" style="color: #808080;"></i></a><a class="social-icon" href="https://github.com/S-tanley" target="_blank" title="Github"><i class="fab fa-github" style="color: #808080;"></i></a><a class="social-icon" href="mailto:zbowen936@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #808080;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Summary</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract-Introduction-Background"><span class="toc-number">1.1.</span> <span class="toc-text">Abstract &amp; Introduction &amp; Background</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Challenges-and-Proposed-Solutions"><span class="toc-number">1.2.</span> <span class="toc-text">Challenges and Proposed Solutions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ORCA-Design-Implementation"><span class="toc-number">1.3.</span> <span class="toc-text">ORCA Design &amp; Implementation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Evaluation-Related-Work-and-Discussion-Conclusion"><span class="toc-number">1.4.</span> <span class="toc-text">Evaluation &amp; Related Work and Discussion &amp; Conclusion</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">Thoughts</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Confusion"><span class="toc-number">2.1.</span> <span class="toc-text">Confusion</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#About-Figure-1"><span class="toc-number">2.1.1.</span> <span class="toc-text">About Figure 1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#About-batching"><span class="toc-number">2.1.2.</span> <span class="toc-text">About batching</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#How-to-batch-requests-together"><span class="toc-number">2.1.2.1.</span> <span class="toc-text">How to batch requests together</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#About-Figure-5"><span class="toc-number">2.1.2.2.</span> <span class="toc-text">About Figure 5</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#About-the-scheduling-algorithms"><span class="toc-number">2.1.3.</span> <span class="toc-text">About the scheduling algorithms</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#first-come-first-served-FCFS"><span class="toc-number">2.1.3.1.</span> <span class="toc-text">first-come-first-served (FCFS)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#max-tokens-attribute"><span class="toc-number">2.1.3.2.</span> <span class="toc-text">max_tokens attribute</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ideas"><span class="toc-number">2.2.</span> <span class="toc-text">Ideas</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#About-the-iteration-level-scheduling"><span class="toc-number">2.2.1.</span> <span class="toc-text">About the &quot;iteration level scheduling &quot;</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blogs/2025/10/15/Statistics---Why%20We%20Use%20the%20t-Distribution%20to%20Estimate%20the%20Population%20Mean/" title="Statistics---Why We Use the t-Distribution to Estimate the Population Mean">Statistics---Why We Use the t-Distribution to Estimate the Population Mean</a><time datetime="2025-10-15T05:00:00.000Z" title="Created 2025-10-15 00:00:00">2025-10-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blogs/2025/10/14/Statistics---Unbiasedness%20and%20Consistency/" title="Statistics---Unbiasedness and Consistency">Statistics---Unbiasedness and Consistency</a><time datetime="2025-10-14T05:00:00.000Z" title="Created 2025-10-14 00:00:00">2025-10-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blogs/2025/10/14/Statistics---Sufficiency/" title="Statistics---Sufficiency">Statistics---Sufficiency</a><time datetime="2025-10-14T05:00:00.000Z" title="Created 2025-10-14 00:00:00">2025-10-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blogs/2025/10/14/Statistics---%E5%85%8B%E6%8B%89%E9%BB%98-%E6%8B%89%E5%A5%A5%E4%B8%8B%E9%99%90%20(Crame%CC%81r-Rao%20Lower%20Bound,%20CRLB)/" title="Statistics---å…‹æ‹‰é»˜-æ‹‰å¥¥ä¸‹é™ï¼ˆCramÃ©r-Rao Lower Bound, CRLBï¼‰">Statistics---å…‹æ‹‰é»˜-æ‹‰å¥¥ä¸‹é™ï¼ˆCramÃ©r-Rao Lower Bound, CRLBï¼‰</a><time datetime="2025-10-14T05:00:00.000Z" title="Created 2025-10-14 00:00:00">2025-10-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blogs/2025/10/12/Operating%20Systems%20Notes:%20The%20Path%20to%20the%20Kernel/" title="Operating Systems Notes: The Path to the Kernel">Operating Systems Notes: The Path to the Kernel</a><time datetime="2025-10-12T05:00:00.000Z" title="Created 2025-10-12 00:00:00">2025-10-12</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Stanley Zheng</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll to Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/blogs/js/utils.js"></script><script src="/blogs/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (false) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = {"data-mapping":"pathname","data-input-position":"top","data-reactions-enabled":1,"data-strict":1}

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'S-tanley/blogs',
      'data-repo-id': 'R_kgDOOPJb6Q',
      'data-category-id': 'DIC_kwDOOPJb6c4CohlA',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null
  const getUtterancesTheme = theme => theme === 'dark' ? 'photon-dark' : 'github-light'

  const loadUtterances = (el = document, key) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyUtterances = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const config = {
      src: 'https://utteranc.es/client.js',
      repo: 'S-tanley/blogs',
      theme: getUtterancesTheme(document.documentElement.getAttribute('data-theme')),
      crossorigin: 'anonymous',
      async: true,
      ...option,
      'issue-term': isShuoshuo ? key : (option && option['issue-term']) || 'pathname'
    }

    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => ele.setAttribute(key, value))
    el.querySelector('#utterances-wrap').appendChild(ele)
  }

  const changeUtterancesTheme = theme => {
    const iframe = document.querySelector('#utterances-wrap iframe')
    if (iframe) {
      const message = {
        type: 'set-theme',
        theme: getUtterancesTheme(theme)
      };
      iframe.contentWindow.postMessage(message, 'https://utteranc.es')
    }
  }

  btf.addGlobalFn('themeChange', changeUtterancesTheme, 'utterances')

  if (isShuoshuo) {
    'Giscus' === 'Utterances'
      ? window.shuoshuoComment = { loadComment: loadUtterances }
      : window.loadOtherComment = loadUtterances
    return
  }
  
  if ('Giscus' === 'Utterances' || !false) {
    if (false) btf.loadComment(document.getElementById('utterances-wrap'), loadUtterances)
    else loadUtterances()
  } else {
    window.loadOtherComment = loadUtterances
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/blogs/js/search/local-search.js"></script></div></div></body></html>